[{"content":"My New Weekend Project: Building a Personal Ad-Blocking Server in the Cloud! Hey everyone, Prajwol here.\nLike a lot of you, I spend a good chunk of my day online. And lately, it\u0026rsquo;s felt like I\u0026rsquo;m in a constant battle with pop-ups, trackers, and auto-playing video ads. I\u0026rsquo;ve used browser extensions for years, but I wanted a more powerful solution‚Äîsomething that would protect my entire home network, including my phone and smart TV, without needing to install software everywhere.\nSo, I decided to take on a new project: building my very own ad-blocking DNS server in the cloud.\nI\u0026rsquo;d done something similar a while back with Linode, but this time I wanted to dive into the world of Amazon Web Services (AWS) and see if I could build a reliable, secure, and cost-effective setup from scratch. It turned into quite the adventure, involving a late-night session of launching a virtual server, wrestling with firewalls, and securing my own private domain with an SSL certificate.\nThe end result? It\u0026rsquo;s been fantastic. My web pages load noticeably faster, and the general online experience feels so much cleaner and less intrusive. Plus, knowing that I have full control over my own corner of the internet is incredibly satisfying. It\u0026rsquo;s a great feeling to see the query logs fill up with blocked requests for domains I\u0026rsquo;ve never even heard of!\nI documented every single step of my journey, from the first click in the AWS console to the final configuration on my home router. If you\u0026rsquo;re curious about how to build one for yourself, I\u0026rsquo;ve written up a complete, step-by-step guide.\nYou can check out the full project guide here! It was a challenging but really rewarding project. Let me know what you think!\nPublished: Friday, August 22, 2025\n","permalink":"http://localhost:1313/blog/adguard-aws/","summary":"\u003ch1 id=\"my-new-weekend-project-building-a-personal-ad-blocking-server-in-the-cloud\"\u003eMy New Weekend Project: Building a Personal Ad-Blocking Server in the Cloud!\u003c/h1\u003e\n\u003cp\u003eHey everyone, Prajwol here.\u003c/p\u003e\n\u003cp\u003eLike a lot of you, I spend a good chunk of my day online. And lately, it\u0026rsquo;s felt like I\u0026rsquo;m in a constant battle with pop-ups, trackers, and auto-playing video ads. I\u0026rsquo;ve used browser extensions for years, but I wanted a more powerful solution‚Äîsomething that would protect my entire home network, including my phone and smart TV, without needing to install software everywhere.\u003c/p\u003e","title":"Building a Personal Ad-Blocking Server in the Cloud!"},{"content":"Your Personal Internet Guardian: How to Build a FREE Ad-Blocker in the Cloud! üöÄ Hey everyone! A while back, I wrote a guide on setting up AdGuard Home on Linode. The world of tech moves fast, and it\u0026rsquo;s time for an upgrade! Today, we\u0026rsquo;re going to build our own powerful, network-wide ad-blocker using Amazon Web Services (AWS), and we\u0026rsquo;ll make it secure with our own domain and SSL certificate.\nThink of this as building a digital gatekeeper for your internet. Before any ads, trackers, or malicious sites can reach your devices, our AdGuard Home server will slam the door shut. The best part? This works on your phone, laptop, smart TV‚Äîanything on your network‚Äîwithout installing a single app on them.\nThis guide is for everyone, from seasoned tech wizards to curious beginners. We\u0026rsquo;ll break down every step in simple terms, so grab a coffee, and let\u0026rsquo;s build something awesome!\n## Chapter 1: Building Our Home in the AWS Cloud ‚òÅÔ∏è First, we need a server. We\u0026rsquo;ll use an Amazon EC2 instance, which is just a fancy name for a virtual computer that you rent.\nSign Up for AWS: If you don\u0026rsquo;t have an account, head to the AWS website and sign up. You\u0026rsquo;ll need a credit card for verification, but for this guide, we can often stay within the Free Tier.\nLaunch Your EC2 Instance:\nLog in to your AWS Console and search for EC2. Click \u0026ldquo;Launch instance\u0026rdquo;. Name: Give your server a cool name, like AdGuard-Server. Application and OS Images: In the search bar, type Debian and select the latest version (e.g., Debian 12). Make sure it\u0026rsquo;s marked \u0026ldquo;Free tier eligible\u0026rdquo;. Instance Type: Choose t2.micro. This is your free, trusty little server. Key Pair (for login): This is your digital key to the server\u0026rsquo;s front door. Click \u0026ldquo;Create a new key pair\u0026rdquo;, name it something like my-adguard-key, and download the .pem file. Keep this file secret and safe! Network settings (The Firewall): This is crucial. We need to tell our server which doors to open. Click \u0026ldquo;Edit\u0026rdquo;. Check the box for \u0026ldquo;Allow SSH traffic from\u0026rdquo; and select My IP. This lets you securely log in. Check \u0026ldquo;Allow HTTPS traffic from the internet\u0026rdquo; and \u0026ldquo;Allow HTTP traffic from the internet\u0026rdquo;. We\u0026rsquo;ll need these for our secure dashboard later. Launch It! Hit the \u0026ldquo;Launch instance\u0026rdquo; button and watch as your new cloud server comes to life.\nGive Your Server a Permanent Address (Elastic IP):\nBy default, your server\u0026rsquo;s public IP address will change every time it reboots. Let\u0026rsquo;s make it permanent! In the EC2 menu on the left, go to \u0026ldquo;Elastic IPs\u0026rdquo;. Click \u0026ldquo;Allocate Elastic IP address\u0026rdquo; and then \u0026ldquo;Allocate\u0026rdquo;. Select the new IP address from the list, click \u0026ldquo;Actions\u0026rdquo;, and then \u0026ldquo;Associate Elastic IP address\u0026rdquo;. Choose your AdGuard-Server instance from the list and click \u0026ldquo;Associate\u0026rdquo;. Your server now has a static IP address that will never change! Make a note of this new IP. ## Chapter 2: Opening the Doors (Configuring the Firewall) üö™ Our server is running, but we need to open a few more specific doors for AdGuard Home to work.\nGo to your EC2 Instance details, click the \u0026ldquo;Security\u0026rdquo; tab, and click on the Security Group name. Click \u0026ldquo;Edit inbound rules\u0026rdquo; and \u0026ldquo;Add rule\u0026rdquo; for each of the following: Port 3000: Custom TCP, Port 3000, Source My IP. (For the initial setup). Port 53 (TCP): Custom TCP, Port 53, Source Anywhere-IPv4. (For DNS). Port 53 (UDP): Custom UDP, Port 53, Source Anywhere-IPv4. (Also for DNS). Port 853: Custom TCP, Port 853, Source Anywhere-IPv4. (For DNS-over-TLS). Click \u0026ldquo;Save rules\u0026rdquo;. Your firewall is now ready! ## Chapter 3: Installing AdGuard Home üõ°Ô∏è Now, let\u0026rsquo;s connect to our server and install the magic software.\nConnect via SSH: Open a terminal (PowerShell on Windows, Terminal on Mac/Linux) and use the key you downloaded to connect. Use your new Elastic IP address! # Replace the path and Elastic IP with your own ssh -i \u0026#34;path/to/my-adguard-key.pem\u0026#34; admin@YOUR_ELASTIC_IP Install AdGuard Home: Run this one simple command. It downloads and installs everything for you. curl -s -S -L [https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh](https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh) | sh -s -- -v Run the Setup Wizard: The script will give you a link, like http://YOUR_ELASTIC_IP:3000. Open this in your browser. Follow the on-screen steps to create your admin username and password. ## Chapter 4: Teaching Your Guardian Who to Trust and What to Block With AdGuard Home installed, the next step is to configure its core brain: the DNS servers it gets its answers from and the blocklists it uses to protect your network.\n1. Setting Up Upstream DNS Servers Think of \u0026ldquo;Upstream DNS Servers\u0026rdquo; as the giant, public phonebooks of the internet. When your AdGuard server doesn\u0026rsquo;t know an address (and it\u0026rsquo;s not on a blocklist), it asks one of these upstreams. It\u0026rsquo;s recommended to use a mix of the best encrypted DNS providers for security, privacy, and speed.\nIn the AdGuard dashboard, go to Settings -\u0026gt; DNS settings. In the \u0026ldquo;Upstream DNS servers\u0026rdquo; box, enter the following, one per line:\nhttps://dns.quad9.net/dns-query https://dns.google/dns-query https://dns.cloudflare.com/dns-query Quad9: Focuses heavily on security, blocking malicious domains. Google: Known for being very fast. Cloudflare: A great all-around choice with a strong focus on privacy. 2. Optimizing DNS Performance Still in the DNS settings page, scroll down to optimize how your server queries the upstreams.\nParallel requests: Select this option. This is the fastest and most resilient mode. It sends your DNS query to all three of your upstream servers at the same time and uses the answer from the very first one that responds. This ensures you always get the quickest possible result.\nEnable EDNS client subnet (ECS): Check this box. This is very important for services like Netflix, YouTube, and other content delivery networks (CDNs). It helps them give you content from a server that is geographically closest to you, resulting in faster speeds and a better experience.\n3. Enabling DNSSEC Right below the upstream servers, there\u0026rsquo;s a checkbox for \u0026ldquo;Enable DNSSEC\u0026rdquo;. You should check this box. DNSSEC is like a digital wax seal on a letter; it verifies that the DNS answers you\u0026rsquo;re getting are authentic and haven\u0026rsquo;t been tampered with. It\u0026rsquo;s a simple, one-click security boost.\n4. Choosing Your Blocklists This is the fun part‚Äîthe actual ad-blocking! Go to Filters -\u0026gt; DNS blocklists. For a \u0026ldquo;Balanced \u0026amp; Powerful\u0026rdquo; setup that blocks aggressively without a high risk of breaking websites, enable the following lists:\nAdGuard DNS filter: A great, well-maintained baseline. OISD Blocklist Big: Widely considered one of the best all-in-one lists for blocking ads, trackers, and malware. HaGeZi\u0026rsquo;s Pro Blocklist: A fantastic list that adds another layer of aggressive blocking for privacy. HaGeZi\u0026rsquo;s Threat Intelligence Feed: A crucial security-only list that focuses on protecting against active threats like phishing and malware. This combination will give you robust protection against both annoyances and real dangers.\n## Chapter 5: Giving Your Server a Name (Free Domain with No-IP) üìõ An IP address is hard to remember. Let\u0026rsquo;s get a free, memorable name for our server.\nSign Up at No-IP: Go to No-IP.com, create a free account, and create a hostname (e.g., my-dns.ddns.net). Point it to Your Server: When creating the hostname, enter your server\u0026rsquo;s permanent Elastic IP address. Confirm your account via email. ## Chapter 6: Making It Secure with SSL/TLS üîê We\u0026rsquo;ll use Let\u0026rsquo;s Encrypt and Certbot to get a free SSL certificate, which lets us use secure https:// and encrypted DNS.\nInstall Certbot: In your SSH session, run these commands:\nsudo apt update sudo apt install certbot -y Get the Certificate: Run this command, replacing the email and domain with your own.\n# This command will temporarily stop any service on port 80, get the certificate, and then finish. sudo certbot certonly --standalone --agree-tos --email YOUR_EMAIL@example.com -d your-no-ip-hostname.ddns.net If it\u0026rsquo;s successful, it will tell you where your certificate files are saved (usually in /etc/letsencrypt/live/your-no-ip-hostname.ddns.net/).\nConfigure AdGuard Home Encryption:\nGo to your AdGuard Home dashboard (Settings -\u0026gt; Encryption settings). Check \u0026ldquo;Enable encryption\u0026rdquo;. In the \u0026ldquo;Server name\u0026rdquo; field, enter your No-IP hostname. Under \u0026ldquo;Certificates\u0026rdquo;, choose \u0026ldquo;Set a certificates file path\u0026rdquo;. Certificate path: /etc/letsencrypt/live/your-no-ip-hostname.ddns.net/fullchain.pem Private key path: /etc/letsencrypt/live/your-no-ip-hostname.ddns.net/privkey.pem Click \u0026ldquo;Save configuration\u0026rdquo;. The page will reload on a secure https:// connection! ## Chapter 7: Automating SSL Renewal (Cron Job Magic) ‚ú® Let\u0026rsquo;s Encrypt certificates last for 90 days. We can tell our server to automatically renew them.\nOpen the Cron Editor: In SSH, run sudo crontab -e and choose nano as your editor. Add the Renewal Job: Add this line to the bottom of the file. It tells the server to try renewing the certificate every day at 2:30 AM. 30 2 * * * systemctl stop AdGuardHome.service \u0026amp;\u0026amp; certbot renew --quiet \u0026amp;\u0026amp; systemctl start AdGuardHome.service Save and exit (Ctrl+X, then Y, then Enter). Your server will now keep its certificate fresh forever! ## Chapter 8: Testing Your New Superpowers (DoH \u0026amp; DoT) üß™ For a direct confirmation, I used these commands on my computer:\nDNS-over-HTTPS (DoH) Test: This test checks if the secure web endpoint for DNS is alive.\ncurl -v [https://your-no-ip-hostname.ddns.net/dns-query](https://your-no-ip-hostname.ddns.net/dns-query) I got a \u0026ldquo;405 Method Not Allowed\u0026rdquo; error, which sounds bad but is actually great news. It means I successfully connected to the server, which correctly told me I didn\u0026rsquo;t send a real query. The connection works!\nDNS-over-TLS (DoT) Test: This checks the dedicated secure port for DNS. I used a tool called kdig.\n# I had to install it first with: sudo apt install knot-dnsutils kdig @your-no-ip-hostname.ddns.net +tls-ca +tls-host=your-no-ip-hostname.ddns.net example.com The command returned a perfect DNS answer for example.com, confirming the secure tunnel was working.\n## Chapter 9: Protecting Your Kingdom (Router \u0026amp; Phone Setup) üè∞ Now, let\u0026rsquo;s point your devices to their new guardian.\nOn Your Home Router: Log in to your router\u0026rsquo;s admin page, find the DNS settings, and enter your server\u0026rsquo;s Elastic IP as the primary DNS server. Leave the secondary field blank! This forces all devices on your Wi-Fi to be protected. Then, restart your router. On Your Mobile Phone: Android: Go to Settings -\u0026gt; Network -\u0026gt; Private DNS. Choose \u0026ldquo;Private DNS provider hostname\u0026rdquo; and enter your No-IP hostname (my-dns.ddns.net). This gives you ad-blocking everywhere, even on cellular data! iOS: You can use a profile to configure DoH. A simple way is to use a site like AdGuard\u0026rsquo;s DNS profile generator, but enter your own server\u0026rsquo;s DoH address (https://my-dns.ddns.net/dns-query). ## Chapter 10: The Ultimate Safety Net (Creating a Snapshot) üì∏ Finally, let\u0026rsquo;s back up our perfect setup.\nIn the EC2 Console, go to your instance details. Click the \u0026ldquo;Storage\u0026rdquo; tab and click the \u0026ldquo;Volume ID\u0026rdquo;. Click \u0026ldquo;Actions\u0026rdquo; -\u0026gt; \u0026ldquo;Create snapshot\u0026rdquo;. Give it a description, like AdGuard-Working-Setup-Backup. If you ever mess something up, you can use this snapshot to restore your server to this exact working state in minutes.\n## Bonus Chapter: Common Troubleshooting Tips If things aren\u0026rsquo;t working, here are a few common pitfalls to check:\nBrowser Overrides Everything: If one device isn\u0026rsquo;t blocking ads, check its browser settings! Modern browsers like Chrome have a \u0026ldquo;Secure DNS\u0026rdquo; feature that can bypass your custom setup. You may need to turn this off. Check Your Laptop\u0026rsquo;s DNS: Make sure your computer\u0026rsquo;s network settings are set to \u0026ldquo;Obtain DNS automatically\u0026rdquo; so it listens to the router. A manually set DNS on your PC will ignore the router\u0026rsquo;s settings. Beware of IPv6: If you run into trouble on one device, try disabling IPv6 in that device\u0026rsquo;s Wi-Fi adapter properties to force it to use your working IPv4 setup. ## It‚Äôs a Wrap! And there you have it! You\u0026rsquo;ve successfully built a personal, secure, ad-blocking DNS server in the cloud. You\u0026rsquo;ve learned about cloud computing, firewalls, DNS, SSL, and automation. Go enjoy a faster, cleaner, and more private internet experience.\n","permalink":"http://localhost:1313/projects/adguard-updated/","summary":"\u003ch1 id=\"your-personal-internet-guardian-how-to-build-a-free-ad-blocker-in-the-cloud-\"\u003eYour Personal Internet Guardian: How to Build a FREE Ad-Blocker in the Cloud! üöÄ\u003c/h1\u003e\n\u003cp\u003eHey everyone! A while back, I wrote a guide on setting up AdGuard Home on Linode. The world of tech moves fast, and it\u0026rsquo;s time for an upgrade! Today, we\u0026rsquo;re going to build our own powerful, network-wide ad-blocker using \u003cstrong\u003eAmazon Web Services (AWS)\u003c/strong\u003e, and we\u0026rsquo;ll make it secure with our own domain and SSL certificate.\u003c/p\u003e\n\u003cp\u003eThink of this as building a digital gatekeeper for your internet. Before any ads, trackers, or malicious sites can reach your devices, our AdGuard Home server will slam the door shut. The best part? This works on your phone, laptop, smart TV‚Äîanything on your network‚Äîwithout installing a single app on them.\u003c/p\u003e","title":"How I Built My Own Ad-Blocking DNS Server in the Cloud (2025 Updated Edition!)"},{"content":"Introduction Welcome to the first post in my new homelab series! I\u0026rsquo;ve always been fascinated by self-hosting and DevOps, and I believe the best way to learn is by doing. In this series, I\u0026rsquo;ll document my journey of turning an old, unused laptop into a powerful, efficient, and secure bare-metal server for hosting a variety of network services.\nThe goal for this first part is to lay a solid foundation. We\u0026rsquo;ll take an old laptop, install a minimal and stable Linux operating system, perform some initial security hardening, and set up Docker as our containerization engine. By the end of this post, we\u0026rsquo;ll have a perfect blank canvas ready for the exciting services we\u0026rsquo;ll deploy in the upcoming parts.\n1. Choosing the Hardware \u0026amp; OS Why an Old Laptop? Before diving in, why use an old laptop instead of a Raspberry Pi or a dedicated server? For a starter homelab, a laptop has three huge advantages:\nCost-Effective: It\u0026rsquo;s free if you have one lying around! Built-in UPS: The battery acts as a built-in Uninterruptible Power Supply (UPS), keeping the server running through short power outages. Low Power Consumption: Laptop hardware is designed to be power-efficient, which is great for a device that will be running 24/7. Why Debian 13 \u0026ldquo;Trixie\u0026rdquo;? For the operating system, I chose Debian. It\u0026rsquo;s renowned for its stability, security, and massive package repository. It‚Äôs the bedrock of many other distributions (like Ubuntu) and is perfect for a server because it\u0026rsquo;s lightweight and doesn\u0026rsquo;t include unnecessary software. We\u0026rsquo;ll be using the minimal \u0026ldquo;net-install\u0026rdquo; to ensure we only install what we absolutely need.\n2. Installation and Network Configuration The installation process is straightforward, but the network setup is key to a reliable server.\nMinimal Installation Create a Bootable USB: I downloaded the Debian 13 \u0026ldquo;netinst\u0026rdquo; ISO from the official website and used Rufus on Windows to create a bootable USB drive. Boot from USB: I plugged the USB into the laptop and booted from it (usually pressing F12, F2, or Esc during startup to select the USB device). Language, Location, and Keyboard: Selected English, United States, and the default keyboard layout. Network Setup: Connected the laptop to my home network (Ethernet preferred for stability). Hostname \u0026amp; Domain: Entered a short, memorable hostname for the server (e.g., homelab) and left the domain blank. User Accounts: Set a root password. Created a non-root regular user (this will be used for daily management). Partition Disks: Chose Guided ‚Äì use entire disk with separate /home partition. This is simpler for a server setup. Software Selection: At the ‚ÄúSoftware selection‚Äù screen: Unchecked ‚ÄúDebian desktop environment‚Äù Checked ‚ÄúSSH server‚Äù and ‚Äústandard system utilities‚Äù This ensures a clean command-line system that can be accessed remotely. GRUB Bootloader: Installed GRUB on the primary drive (so the system boots correctly). Finish Installation: Removed the USB drive when prompted and rebooted into the fresh Debian install. Setting a Static IP A server needs a permanent, unchanging IP address. The best way to do this is with DHCP Reservation on your router. This tells your router to always assign the same IP address to your server\u0026rsquo;s unique MAC address.\nFirst, find your laptop‚Äôs current IP address and network interface name by running:\nip a You‚Äôll see output similar to:\n2: enp3s0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\rinet 192.168.0.45/24 brd 192.168.0.255 scope global dynamic enp3s0\rvalid_lft 86396sec preferred_lft 86396sec In this example:\nInterface name: enp3s0 Current IP: 192.168.0.45 MAC address: shown under link/ether in the same section. With this info, log into your router‚Äôs admin panel, find the \u0026ldquo;DHCP Reservation\u0026rdquo; or \u0026ldquo;Static Leases\u0026rdquo; section, and assign a memorable IP address (e.g., 192.168.0.45) to your server‚Äôs MAC address.\nThis ensures the server always gets the same IP from your router, making it easy to find on your network.\nConnecting Remotely with SSH With a static IP set, all future management will be done remotely using an SSH client. For Windows, I highly recommend Solar-PuTTY. I created a new session, entered the server\u0026rsquo;s static IP address, my username, and password, and connected.\n3. Initial Server Hardening With a remote SSH session active, the first thing to do is secure the server and configure it for its headless role.\nUpdate the System First, let\u0026rsquo;s make sure all packages are up to date.\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y Configure the Firewall ufw (Uncomplicated Firewall) is perfect for a simple setup. We\u0026rsquo;ll set it to deny all incoming traffic by default and only allow SSH connections.\n# Install UFW sudo apt install ufw -y # Allow SSH connections sudo ufw allow ssh # Enable the firewall sudo ufw enable Configure Lid-Close Action To ensure the laptop keeps running when the lid is closed, we edit the logind.conf file.\nsudo nano /etc/systemd/logind.conf Uncomment the line:\nHandleLidSwitch=ignore Save the file, then restart the service:\nsudo systemctl restart systemd-logind.service 4. Installing the Containerization Engine: Docker Instead of installing applications directly on our host, we\u0026rsquo;ll use Docker to keep the system clean and make management easier.\nInstall Docker Engine The official convenience script is the easiest way to get the latest version.\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh Add User to Docker Group To run docker commands without sudo, add your user to the docker group. The $USER variable automatically uses the currently logged-in user.\nsudo usermod -aG docker $USER After this, log out and log back in for the change to take effect.\nInstall Docker Compose Docker Compose is essential for managing multi-container applications with a simple YAML file.\nsudo apt install docker-compose-plugin -y To verify the installation:\ndocker compose version Conclusion And that\u0026rsquo;s it for Part 1! We\u0026rsquo;ve successfully turned an old piece of hardware into a hardened, modern server running Debian and Docker with a reliable network configuration. We have a solid and secure foundation to build upon.\nIn the next part of the series, we\u0026rsquo;ll deploy our first critical service: a local, network-wide ad-blocking DNS resolver using AdGuard Home. Stay tuned!\n","permalink":"http://localhost:1313/projects/homelab-series-part-1-debian-docker-foundation/","summary":"\u003ch3 id=\"introduction\"\u003eIntroduction\u003c/h3\u003e\n\u003cp\u003eWelcome to the first post in my new homelab series! I\u0026rsquo;ve always been fascinated by self-hosting and DevOps, and I believe the best way to learn is by doing. In this series, I\u0026rsquo;ll document my journey of turning an old, unused laptop into a powerful, efficient, and secure bare-metal server for hosting a variety of network services.\u003c/p\u003e\n\u003cp\u003eThe goal for this first part is to lay a solid foundation. We\u0026rsquo;ll take an old laptop, install a minimal and stable Linux operating system, perform some initial security hardening, and set up Docker as our containerization engine. By the end of this post, we\u0026rsquo;ll have a perfect blank canvas ready for the exciting services we\u0026rsquo;ll deploy in the upcoming parts.\u003c/p\u003e","title":"Part 1: Reviving an Old Laptop with Debian \u0026 Docker"},{"content":"New Project Alert: Running a Powerful AI Locally with Docker! Hey everyone, Prajwol here.\nI\u0026rsquo;ve always been fascinated by the incredible advancements in AI and large language models. While cloud-based models are powerful, I was really curious about what it would take to run a high-performance model right on my own machine. This gives you ultimate privacy, control, and the ability to experiment without limits.\nSo, for my latest project, I decided to dive in and get the DeepSeek-R1 model, a powerful AI, up and running locally using Docker.\nDocker is an amazing tool that lets you package up applications and all their dependencies into a neat little box called a container. This means you can run complex software without the headache of complicated installations or conflicts with other programs on your system. It was the perfect way to tame this powerful AI and get it running smoothly on my Ubuntu machine.\nThe process was a fantastic learning experience, covering everything from setting up Docker to pulling the model and interacting with the AI. It‚Äôs amazing to have that kind of power running on your own hardware.\nI‚Äôve documented my entire process in a detailed, step-by-step guide. If you‚Äôre interested in local AI and want to see how you can run a powerful model yourself, be sure to check it out!\nYou can find the full project guide right here! Let me know what you think of this one!\nPublished: February, 2023\n","permalink":"http://localhost:1313/blog/running-deepseek-r1-on-docker-container-on-ubuntu/","summary":"\u003ch1 id=\"new-project-alert-running-a-powerful-ai-locally-with-docker\"\u003eNew Project Alert: Running a Powerful AI Locally with Docker!\u003c/h1\u003e\n\u003cp\u003eHey everyone, Prajwol here.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;ve always been fascinated by the incredible advancements in AI and large language models. While cloud-based models are powerful, I was really curious about what it would take to run a high-performance model right on my own machine. This gives you ultimate privacy, control, and the ability to experiment without limits.\u003c/p\u003e\n\u003cp\u003eSo, for my latest project, I decided to dive in and get the \u003cstrong\u003eDeepSeek-R1\u003c/strong\u003e model, a powerful AI, up and running locally using \u003cstrong\u003eDocker\u003c/strong\u003e.\u003c/p\u003e","title":"Running a Powerful AI Locally with Docker!"},{"content":"My First Cloud Ad-Blocker: A Look Back at AdGuard Home on Linode Hey everyone, Prajwol here.\nAs I continue to explore different cloud projects, I often think back to the ones that had the biggest impact on my day-to-day life. One of the very first projects that truly changed my internet experience was setting up my own ad-blocking DNS server using AdGuard Home on a Linode instance.\nMy goal was to find a simple, cost-effective way to block ads and trackers across my entire home network. I wanted a \u0026ldquo;set it and forget it\u0026rdquo; solution that would cover every device‚Äîfrom my phone to my smart TV‚Äîwithout needing to install an app on each one. Linode (now Akamai) was the perfect platform for this: straightforward, powerful, and great for hosting a lightweight service like AdGuard Home.\nThe process of spinning up a small server, running a single installation script, and then seeing the query logs light up with blocked requests was incredibly satisfying. It felt like I had taken back a real measure of control over my own network.\nThis project remains a fantastic entry point for anyone wanting to get started with self-hosting and network privacy. I\u0026rsquo;ve kept the original, detailed guide for anyone who wants to follow along.\nYou can find the full step-by-step project guide here! It‚Äôs a rewarding project that delivers tangible results almost immediately. Let me know if you give it a try!\nPublished: Friday, August 22, 2025\n","permalink":"http://localhost:1313/blog/adguard-home-on-cloud/","summary":"\u003ch1 id=\"my-first-cloud-ad-blocker-a-look-back-at-adguard-home-on-linode\"\u003eMy First Cloud Ad-Blocker: A Look Back at AdGuard Home on Linode\u003c/h1\u003e\n\u003cp\u003eHey everyone, Prajwol here.\u003c/p\u003e\n\u003cp\u003eAs I continue to explore different cloud projects, I often think back to the ones that had the biggest impact on my day-to-day life. One of the very first projects that truly changed my internet experience was setting up my own ad-blocking DNS server using AdGuard Home on a Linode instance.\u003c/p\u003e\n\u003cp\u003eMy goal was to find a simple, cost-effective way to block ads and trackers across my entire home network. I wanted a \u0026ldquo;set it and forget it\u0026rdquo; solution that would cover every device‚Äîfrom my phone to my smart TV‚Äîwithout needing to install an app on each one. Linode (now Akamai) was the perfect platform for this: straightforward, powerful, and great for hosting a lightweight service like AdGuard Home.\u003c/p\u003e","title":"My First Cloud Ad-Blocker - A Look Back at AdGuard Home on Linode"},{"content":"What\u0026rsquo;s the buzz about AdGuard Home? Imagine AdGuard Home as your personal internet guardian. This versatile tool blocks ads, trackers, and other online nuisances across all devices connected to your network. Whether you\u0026rsquo;re browsing on your phone, tablet, or computer, AdGuard Home has your back.\nIn today\u0026rsquo;s digital landscape, robust security measures are paramount. Protecting each device shields your family from accidental clicks and malicious attacks, ensuring peace of mind and a secure online environment.\nWhy on the Cloud? While setting up AdGuard Home on your home network is great, installing it on a cloud server like Linode takes things up a notch. Here\u0026rsquo;s why:\nOn-the-Go Protection: Your devices stay protected from ads and trackers, no matter where you are, you can even share it with your family. Centralized Control: Manage and customize your ad-blocking settings from a single dashboard. Enhanced Privacy: Keep your browsing data away from prying eyes. Ready to embark on this ad-free adventure? Let\u0026rsquo;s get started!\nSetting Up The Environment Step 1: Create a Linode Cloud Account Why choose Linode? Through NetworkChuck\u0026rsquo;s referral link, you receive a generous $100 cloud credit - a fantastic start!\nSign Up: Navigate to Linode\u0026rsquo;s signup page and register. Access the Dashboard: Log in and select \u0026lsquo;Linodes\u0026rsquo; from the left-side menu. Create a Linode: Click \u0026lsquo;Create Linode,\u0026rsquo; choose your preferred region, and select an operating system (Debian 11 is a solid choice). Choose a Plan: The Shared 1GB Nanode instance is sufficient for AdGuard Home. Label and Secure: Assign a label to your Linode and set a strong root password. Deploy: Click \u0026lsquo;Create Linode\u0026rsquo; and wait for it to initialize. Once your Linode is up and running, access it via the LISH Console or SSH. (use root as localhost login)\nStep 2: Installing AdGuard Home on Linode Yes, we\u0026rsquo;re already into setting up at this point.\nLog In: Access your Linode using SSH or the LISH Console with your root credentials. Update the system: sudo apt update \u0026amp;\u0026amp; apt upgrade -y Go ahead and copy this command to Install Adguard Home: curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v AdGuard Home is installed and running. You can use CTRL+Shift+V to paste into the terminal.\nStep 3: Configure AdGuard Home Post-installation, you\u0026rsquo;ll see a list of IP addresses with port :3000. Access the Web Interface: Open your browser and navigate to the IP address followed by :3000. If you encounter a security warning, proceed by clicking \u0026ldquo;Continue to site.\u0026rdquo; Initial Setup: Click \u0026lsquo;Get Started\u0026rsquo; and follow the prompts. When uncertain, default settings are typically fine. Set Credentials: Set up the Username and Password. Step 4: Integrate AdGuard Home with Your Router After this, your AdGuard Home is running, but in order to use it on your devices you need to set up inside your home router for all your devices to be protected. For that, I can\u0026rsquo;t walk you through each and every router\u0026rsquo;s settings, but the steps are pretty similar.\nFind your router IP address, you should be able to find it on the back of your router (commonly 192.168.0.1 or 192.169.1.1) enter it into your browser. Login into your router using the credentials mentioned in the back of your router; the default is often admin for both username and password. I suggest you change your default password. Configure DNS Settings: Enable DHCP Server: Ensure your router\u0026rsquo;s DHCP server is active. Set DNS Addresses: Input your AdGuard Home server\u0026rsquo;s IP as the primary DNS (mine was 96.126.113.207). For secondary DNS, options like 1.1.1.1 (Cloudflare), 9.9.9.9 (Quad9), or 8.8.8.8 (Google) are reliable. Save and apply the changes. Fine-Tuning AdGuard Home If you\u0026rsquo;ve done everything till here you should be good, but for those who enjoy customizations, AdGuard Home offers a plethora of settings. Some of the customization I did are:\nSettings Go to Settings -\u0026gt; General Settings: You can enable Parental Control and Safe Search. You can also make your Statistics last longer than 24hrs which is default. Now on Settings -\u0026gt; DNS Settings By default, it uses DNS from quad9 which is pretty good but I suggest you add more. You can click on the list of known DNS providers, which you can choose from. I used: https://dns.quad9.net/dns-query https://dns.google/dns-query https://dns.cloudflare.com/dns-query Enable \u0026lsquo;Load Balancing\u0026rsquo; to distribute queries evenly. Scroll down to \u0026lsquo;DNS server configuration\u0026rsquo; and enable DNSSEC for enhanced security. Click on Save. Filters DNS blocklists Go to Filters -\u0026gt; DNS blocklists, here you can add a blocklist that people have created and use it to block even more things. By default, AdGuard uses the AdGuard DNS filter, and you can add more.\nClick on Add blocklist -\u0026gt; Choose from the list Don\u0026rsquo;t choose too many from the list cause it may slow your internet requests. These are the blocklists I added. And just like that you are blocking more and more things. DNS rewrites Go to Filters -\u0026gt; DNS rewrites, here you can add your own DNS entries, so I added AdGuard here.\nClick on Add DNS rewrite Type in domain adguardforme.local and your IP address for AdGuard Home. And save it. Now, when I want to go on the AdGuard Home dashboard I just type in adguardforme.local and I\u0026rsquo;m into AdGuard, I don\u0026rsquo;t have to remember the IP address.\nCustom filtering rules Go to Filters -\u0026gt; Custom filtering rules. For some reason when I use Facebook on mobile device stories and videos did not load up, so I added custom filtering rules.\n@@||graph.facebook.com^$important ","permalink":"http://localhost:1313/projects/adguard-home-on-cloud/","summary":"\u003ch1 id=\"whats-the-buzz-about-adguard-home\"\u003eWhat\u0026rsquo;s the buzz about AdGuard Home?\u003c/h1\u003e\n\u003cp\u003eImagine AdGuard Home as your personal internet guardian. This versatile tool blocks ads, trackers, and other online nuisances across all devices connected to your network. Whether you\u0026rsquo;re browsing on your phone, tablet, or computer, AdGuard Home has your back.\u003c/p\u003e\n\u003cp\u003eIn today\u0026rsquo;s digital landscape, robust security measures are paramount. Protecting each device shields your family from accidental clicks and malicious attacks, ensuring peace of mind and a secure online environment.\u003c/p\u003e","title":"Running Private Adguard Server on Cloud (Linode)"},{"content":"What\u0026rsquo;s a Docker Container? Before we dive into setting up DeepSeek-R1, let me explain what a Docker container is. Imagine you have a toy that works perfectly on your birthday but gets broken if you move it to another room. A Docker container is like a magic box that keeps your AI model (the toy) in perfect condition wherever you take it, whether it\u0026rsquo;s running as a background task, on a web server, or even in the cloud.\nDocker containers encapsulate everything required to run an application: the code, dependencies, and environment settings. This ensures consistency across different machines, which is super important for AI models that rely on precise configurations.\nSetting Up The Environment Step 1: Install Ubuntu on Windows (If You Haven\u0026rsquo;t Already) If you\u0026rsquo;re using Windows, the easiest way to get an Ubuntu environment is through the Microsoft Store. Here\u0026rsquo;s how:\nOpen the Microsoft Store and search for Ubuntu. Click Get and let it install. Once installed, open Ubuntu from the Start menu and follow the setup instructions. Update the system: sudo apt update \u0026amp;\u0026amp; sudo apt upgrade Now, you have an Ubuntu terminal running on Windows!\nStep 2: Install Docker (If You Haven\u0026rsquo;t Already) First, let\u0026rsquo;s check if you have Docker installed. Open a terminal and run:\ndocker --version If that returns a version number, congrats! If not, install Docker:\nsudo apt update \u0026amp;\u0026amp; sudo apt install docker.io -y sudo systemctl enable --now docker Step 3: Prerequisites for NVIDIA GPU Install NVIDIA Container Toolkit:\nConfiguring the production repository: curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed \u0026#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g\u0026#39; | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list Update the package list: sudo apt-get update Install the NVIDIA Container Toolkit: sudo apt-get install -y nvidia-container-toolkit Running Ollama Inside Docker Run these commands(P.S. shoutout to NetworkChuck):\ndocker run -d \\ --gpus all \\ -v ollama:/root/.ollama \\ -p 11434:11434 \\ --security-opt=no-new-privileges \\ --cap-drop=ALL \\ --cap-add=SYS_NICE \\ --memory=8g \\ --memory-swap=8g \\ --cpus=4 \\ --read-only \\ --name ollama \\ ollama/ollama Running DeepSeek-R1 Locally Time to bring DeepSeek-R1 to life locally and containerized:\ndocker exec -it ollama ollama run deepseek-r1 or you can run other versions of deepseek-r1 just by typing in the version at the end after a colon(:)\ndocker exec -it ollama ollama run deepseek-r1:7b After this, play around with the AI, if you wanna exit just type:\n/bye Starting Deepseek-R1 To Start Deepseek-R1 from next time go to Ubuntu and type:\ndocker start ollama this will start ollama docker container; then type:\ndocker exec -it ollama ollama run deepseek-r1:7b ","permalink":"http://localhost:1313/projects/running-deepseek-r1-on-docker-container-on-ubuntu/","summary":"\u003ch1 id=\"whats-a-docker-container\"\u003eWhat\u0026rsquo;s a Docker Container?\u003c/h1\u003e\n\u003cp\u003eBefore we dive into setting up DeepSeek-R1, let me explain what a Docker container is. Imagine you have a toy that works perfectly on your birthday but gets broken if you move it to another room. A Docker container is like a magic box that keeps your AI model (the toy) in perfect condition wherever you take it, whether it\u0026rsquo;s running as a background task, on a web server, or even in the cloud.\u003c/p\u003e","title":"Dive into AI Fun: Running DeepSeek-R1 on a Docker Container on Ubuntu"},{"content":"Description I joined AbbVie initially as a contractor and quickly demonstrated the skills and dedication that led to my conversion to a full-time position. In my role, I stepped into a high-stakes production environment where precision and operational stability are paramount. My work centered on the optimization and maintenance of sophisticated, machine learning-based visual inspection systems. I was responsible for fine-tuning these models, analyzing their performance data, and troubleshooting complex technical issues across both hardware and software, including the POM and PCE systems.\nThis wasn\u0026rsquo;t just about keeping machines running; it was about enhancing them. By applying a systematic, data-driven approach, I contributed to a 30% reduction in product waste, a metric that translates directly to improved efficiency and sustainability. Working within strict GMPs and utilizing systems like SAP for material tracking, I learned to balance technical problem-solving with rigorous compliance, ensuring that every action contributed to the stability and reliability of mission-critical operations.\n","permalink":"http://localhost:1313/experience/abbvie/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eI joined AbbVie initially as a contractor and quickly demonstrated the skills and dedication that led to my conversion to a full-time position. In my role, I stepped into a high-stakes production environment where precision and operational stability are paramount. My work centered on the optimization and maintenance of sophisticated, machine learning-based visual inspection systems. I was responsible for fine-tuning these models, analyzing their performance data, and troubleshooting complex technical issues across both hardware and software, including the POM and PCE systems.\u003c/p\u003e","title":"Operator III"},{"content":"Description As my first professional role after moving to the United States, my position at FedEx was a crucial step in adapting my technical skills to a new corporate environment. My journey began as a contractor, where my performance and analytical skills in a fast-paced setting led to my transition to a full-time Associate role. At the device testing center, I was on the front lines of quality assurance for a wide array of consumer electronics. I conducted comprehensive, systematic testing on mobile devices, smartwatches, and routers, executing detailed test plans to identify hardware vulnerabilities, software bugs, and non-compliance with network standards.\nMy responsibilities included meticulously documenting my findings, reproducing bugs to assist developers, and providing clear, actionable reports to engineering teams. This collaborative process was crucial in accelerating the repair cycle and ensuring that products met the highest standards of quality and security before reaching the market. The role sharpened my analytical skills and gave me a deep appreciation for the importance of rigorous testing in the software development lifecycle.\n","permalink":"http://localhost:1313/experience/fedex/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eAs my first professional role after moving to the United States, my position at FedEx was a crucial step in adapting my technical skills to a new corporate environment. My journey began as a contractor, where my performance and analytical skills in a fast-paced setting led to my transition to a full-time Associate role. At the device testing center, I was on the front lines of quality assurance for a wide array of consumer electronics. I conducted comprehensive, systematic testing on mobile devices, smartwatches, and routers, executing detailed test plans to identify hardware vulnerabilities, software bugs, and non-compliance with network standards.\u003c/p\u003e","title":"Product Testing Associate"},{"content":"Description As the IT Support Specialist for a bustling international college with over 2,500 students and staff, I was at the heart of the campus\u0026rsquo;s technical operations. My role was dynamic and comprehensive, involving end-to-end technical support across a diverse, multi-building campus. I managed the entire user lifecycle, from onboarding new accounts to ensuring smooth system setups across Windows, Linux, and Mac environments. I was the primary point of contact for all technical challenges, resolving Tier 1 and 2 support tickets with a 90% SLA adherence and troubleshooting complex OS issues to minimize downtime.\nMy tenure was marked by significant growth and adaptation. I led the complete technical setup of eight new computer labs, managing everything from hardware deployment and network cabling to software installation and configuration. When the COVID-19 pandemic hit, I was instrumental in transitioning the campus to a hybrid learning model, my first professional experience navigating such a large-scale shift. This required rapidly scaling our remote support capabilities and ensuring both students and faculty could operate effectively from anywhere.\nA cornerstone project of my time was the complete technical overhaul of the newly acquired Kumari Film Hall. I was deeply involved in the project to transform the old cinema into modern lecture halls, which included designing and deploying the entire network infrastructure, setting up AV systems, and ensuring seamless integration with the main campus network.\nTo support these expanding operations, I took the lead in deploying a new UVDesk help desk ticketing system on a CentOS server and embraced automation, utilizing tools like OK Goldy to streamline user creation in Google Workspace. These initiatives standardized processes, improved efficiency, and allowed our team to successfully manage the college\u0026rsquo;s ambitious growth.\n","permalink":"http://localhost:1313/experience/islingtoncollege/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eAs the IT Support Specialist for a bustling international college with over 2,500 students and staff, I was at the heart of the campus\u0026rsquo;s technical operations. My role was dynamic and comprehensive, involving end-to-end technical support across a diverse, multi-building campus. I managed the entire user lifecycle, from onboarding new accounts to ensuring smooth system setups across Windows, Linux, and Mac environments. I was the primary point of contact for all technical challenges, resolving Tier 1 and 2 support tickets with a 90% SLA adherence and troubleshooting complex OS issues to minimize downtime.\u003c/p\u003e","title":"IT Support Specialist"},{"content":"Description Building on my foundational experience, my internship at BlackBox Technologies immersed me in a more complex, project-based environment. I was an integral part of a development team tasked with building a web-based attendance system from the ground up. This role provided me with invaluable hands-on, full-stack experience. I contributed to the backend by assisting senior engineers with the development of business logic in .NET, giving me insight into server-side architecture. Simultaneously, I was responsible for building responsive, user-facing components for the front-end using HTML, CSS, and JavaScript.\nThis experience was a deep dive into the software development lifecycle. I learned how to translate business requirements into technical specifications, participated in code reviews, and understood the synergy between front-end and back-end systems. Working in close collaboration with the engineering team on a single, focused product was an excellent opportunity to apply my skills to a real-world project and solidify my understanding of creating robust, scalable web applications.\n","permalink":"http://localhost:1313/experience/blackbox/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eBuilding on my foundational experience, my internship at BlackBox Technologies immersed me in a more complex, project-based environment. I was an integral part of a development team tasked with building a web-based attendance system from the ground up. This role provided me with invaluable hands-on, full-stack experience. I contributed to the backend by assisting senior engineers with the development of business logic in .NET, giving me insight into server-side architecture. Simultaneously, I was responsible for building responsive, user-facing components for the front-end using HTML, CSS, and JavaScript.\u003c/p\u003e","title":"Web Development Intern"},{"content":"Description My journey into professional software development began at Radiant Infotech, my first internship and job in the tech industry. This role was a pivotal transition from academic theory to real-world application. I was entrusted with supporting the full lifecycle of client websites, which provided an immersive learning experience. My primary responsibility was to develop responsive, pixel-perfect front-end interfaces using HTML, CSS, and Bootstrap, translating design files into functional web components. A key part of this process was using Adobe Photoshop to prepare and optimize web graphics, ensuring both aesthetic quality and optimal performance.\nBeyond the initial development, my role extended to managing website content through various CMS platforms and performing rigorous debugging to ensure cross-browser compatibility and a seamless user experience. This foundational internship was crucial in building my confidence and skills in modern web development, teaching me how to collaborate effectively within a team to deliver high-quality digital products for clients.\n","permalink":"http://localhost:1313/experience/radiantinfotech/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eMy journey into professional software development began at Radiant Infotech, my first internship and job in the tech industry. This role was a pivotal transition from academic theory to real-world application. I was entrusted with supporting the full lifecycle of client websites, which provided an immersive learning experience. My primary responsibility was to develop responsive, pixel-perfect front-end interfaces using HTML, CSS, and Bootstrap, translating design files into functional web components. A key part of this process was using Adobe Photoshop to prepare and optimize web graphics, ensuring both aesthetic quality and optimal performance.\u003c/p\u003e","title":"Web Development Intern"},{"content":"Introduction Welcome to my personal portfolio website. I respect your privacy and am committed to protecting it. This policy outlines what information is collected when you visit my site and how that information is used.\nInformation Collection and Use I collect information in two ways: information you provide directly and anonymous data collected by analytics services.\nPersonal Data You Provide When you request a copy of my resume, you are asked to voluntarily provide your email address.\nHow it\u0026rsquo;s collected: This information is collected via an embedded Google Form. Why it\u0026rsquo;s collected: It is used for the sole purpose of sending the requested resume document to you through an automated process managed by Google Apps Script. How it\u0026rsquo;s used: Your email will not be used for marketing purposes, sold, or shared with any third parties. Anonymous Usage Data To improve the user experience and analyze traffic, this website uses the following third-party services:\nCloudflare Web Analytics: This service collects anonymous traffic data such as page views and country of origin. It does not use cookies or collect personally identifiable information. You can view their privacy policy here.\nMicrosoft Clarity: This service helps me understand user behavior through anonymous session recordings and heatmaps. This data is used to improve the website\u0026rsquo;s design and functionality. You can view their privacy policy here.\nService Providers This website relies on the following third-party service providers to function:\nGoogle Workspace (Forms, Sheets, Apps Script): Used to manage and automate resume requests. Cloudflare \u0026amp; Microsoft: Used for collecting anonymous web analytics. Netlify \u0026amp; GitHub: Used for hosting and deploying the website. Changes to This Privacy Policy I may update this Privacy Policy from time to time. I will notify you of any changes by posting the new Privacy Policy on this page. You are advised to review this page periodically for any changes.\nContact Me If you have any questions about this Privacy Policy, please contact me at: prajwolad18@gmail.com\n","permalink":"http://localhost:1313/privacy-policy/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWelcome to my personal portfolio website. I respect your privacy and am committed to protecting it. This policy outlines what information is collected when you visit my site and how that information is used.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"information-collection-and-use\"\u003eInformation Collection and Use\u003c/h2\u003e\n\u003cp\u003eI collect information in two ways: information you provide directly and anonymous data collected by analytics services.\u003c/p\u003e\n\u003ch3 id=\"personal-data-you-provide\"\u003ePersonal Data You Provide\u003c/h3\u003e\n\u003cp\u003eWhen you request a copy of my resume, you are asked to voluntarily provide your email address.\u003c/p\u003e","title":"Privacy Policy"},{"content":"My New Weekend Project: Building a Personal Ad-Blocking Server in the Cloud! Hey everyone, Prajwol here.\nLike a lot of you, I spend a good chunk of my day online. And lately, it\u0026rsquo;s felt like I\u0026rsquo;m in a constant battle with pop-ups, trackers, and auto-playing video ads. I\u0026rsquo;ve used browser extensions for years, but I wanted a more powerful solution‚Äîsomething that would protect my entire home network, including my phone and smart TV, without needing to install software everywhere.\nSo, I decided to take on a new project: building my very own ad-blocking DNS server in the cloud.\nI\u0026rsquo;d done something similar a while back with Linode, but this time I wanted to dive into the world of Amazon Web Services (AWS) and see if I could build a reliable, secure, and cost-effective setup from scratch. It turned into quite the adventure, involving a late-night session of launching a virtual server, wrestling with firewalls, and securing my own private domain with an SSL certificate.\nThe end result? It\u0026rsquo;s been fantastic. My web pages load noticeably faster, and the general online experience feels so much cleaner and less intrusive. Plus, knowing that I have full control over my own corner of the internet is incredibly satisfying. It\u0026rsquo;s a great feeling to see the query logs fill up with blocked requests for domains I\u0026rsquo;ve never even heard of!\nI documented every single step of my journey, from the first click in the AWS console to the final configuration on my home router. If you\u0026rsquo;re curious about how to build one for yourself, I\u0026rsquo;ve written up a complete, step-by-step guide.\nYou can check out the full project guide here! It was a challenging but really rewarding project. Let me know what you think!\nPublished: Friday, August 22, 2025\n","permalink":"http://localhost:1313/blog/adguard-aws/","summary":"\u003ch1 id=\"my-new-weekend-project-building-a-personal-ad-blocking-server-in-the-cloud\"\u003eMy New Weekend Project: Building a Personal Ad-Blocking Server in the Cloud!\u003c/h1\u003e\n\u003cp\u003eHey everyone, Prajwol here.\u003c/p\u003e\n\u003cp\u003eLike a lot of you, I spend a good chunk of my day online. And lately, it\u0026rsquo;s felt like I\u0026rsquo;m in a constant battle with pop-ups, trackers, and auto-playing video ads. I\u0026rsquo;ve used browser extensions for years, but I wanted a more powerful solution‚Äîsomething that would protect my entire home network, including my phone and smart TV, without needing to install software everywhere.\u003c/p\u003e","title":"Building a Personal Ad-Blocking Server in the Cloud!"},{"content":"Introduction Welcome to the first post in my new homelab series! I\u0026rsquo;ve always been fascinated by self-hosting and DevOps, and I believe the best way to learn is by doing. In this series, I\u0026rsquo;ll document my journey of turning an old, unused laptop into a powerful, efficient, and secure bare-metal server for hosting a variety of network services.\nThe goal for this first part is to lay a solid foundation. We\u0026rsquo;ll take an old laptop, install a minimal and stable Linux operating system, perform some initial security hardening, and set up Docker as our containerization engine. By the end of this post, we\u0026rsquo;ll have a perfect blank canvas ready for the exciting services we\u0026rsquo;ll deploy in the upcoming parts.\n1. Choosing the Hardware \u0026amp; OS Why an Old Laptop? Before diving in, why use an old laptop instead of a Raspberry Pi or a dedicated server? For a starter homelab, a laptop has three huge advantages:\nCost-Effective: It\u0026rsquo;s free if you have one lying around! Built-in UPS: The battery acts as a built-in Uninterruptible Power Supply (UPS), keeping the server running through short power outages. Low Power Consumption: Laptop hardware is designed to be power-efficient, which is great for a device that will be running 24/7. Why Debian 13 \u0026ldquo;Trixie\u0026rdquo;? For the operating system, I chose Debian. It\u0026rsquo;s renowned for its stability, security, and massive package repository. It‚Äôs the bedrock of many other distributions (like Ubuntu) and is perfect for a server because it\u0026rsquo;s lightweight and doesn\u0026rsquo;t include unnecessary software. We\u0026rsquo;ll be using the minimal \u0026ldquo;net-install\u0026rdquo; to ensure we only install what we absolutely need.\n2. Installation and Network Configuration The installation process is straightforward, but the network setup is key to a reliable server.\nMinimal Installation Create a Bootable USB: I downloaded the Debian 13 \u0026ldquo;netinst\u0026rdquo; ISO from the official website and used Rufus on Windows to create a bootable USB drive. Boot from USB: I plugged the USB into the laptop and booted from it (usually pressing F12, F2, or Esc during startup to select the USB device). Language, Location, and Keyboard: Selected English, United States, and the default keyboard layout. Network Setup: Connected the laptop to my home network (Ethernet preferred for stability). Hostname \u0026amp; Domain: Entered a short, memorable hostname for the server (e.g., homelab) and left the domain blank. User Accounts: Set a root password. Created a non-root regular user (this will be used for daily management). Partition Disks: Chose Guided ‚Äì use entire disk with separate /home partition. This is simpler for a server setup. Software Selection: At the ‚ÄúSoftware selection‚Äù screen: Unchecked ‚ÄúDebian desktop environment‚Äù Checked ‚ÄúSSH server‚Äù and ‚Äústandard system utilities‚Äù This ensures a clean command-line system that can be accessed remotely. GRUB Bootloader: Installed GRUB on the primary drive (so the system boots correctly). Finish Installation: Removed the USB drive when prompted and rebooted into the fresh Debian install. Setting a Static IP A server needs a permanent, unchanging IP address. The best way to do this is with DHCP Reservation on your router. This tells your router to always assign the same IP address to your server\u0026rsquo;s unique MAC address.\nFirst, find your laptop‚Äôs current IP address and network interface name by running:\nip a You‚Äôll see output similar to:\n2: enp3s0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\rinet 192.168.0.45/24 brd 192.168.0.255 scope global dynamic enp3s0\rvalid_lft 86396sec preferred_lft 86396sec In this example:\nInterface name: enp3s0 Current IP: 192.168.0.45 MAC address: shown under link/ether in the same section. With this info, log into your router‚Äôs admin panel, find the \u0026ldquo;DHCP Reservation\u0026rdquo; or \u0026ldquo;Static Leases\u0026rdquo; section, and assign a memorable IP address (e.g., 192.168.0.45) to your server‚Äôs MAC address.\nThis ensures the server always gets the same IP from your router, making it easy to find on your network.\nConnecting Remotely with SSH With a static IP set, all future management will be done remotely using an SSH client. For Windows, I highly recommend Solar-PuTTY. I created a new session, entered the server\u0026rsquo;s static IP address, my username, and password, and connected.\n3. Initial Server Hardening With a remote SSH session active, the first thing to do is secure the server and configure it for its headless role.\nUpdate the System First, let\u0026rsquo;s make sure all packages are up to date.\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y Configure the Firewall ufw (Uncomplicated Firewall) is perfect for a simple setup. We\u0026rsquo;ll set it to deny all incoming traffic by default and only allow SSH connections.\n# Install UFW sudo apt install ufw -y # Allow SSH connections sudo ufw allow ssh # Enable the firewall sudo ufw enable Configure Lid-Close Action To ensure the laptop keeps running when the lid is closed, we edit the logind.conf file.\nsudo nano /etc/systemd/logind.conf Uncomment the line:\nHandleLidSwitch=ignore Save the file, then restart the service:\nsudo systemctl restart systemd-logind.service 4. Installing the Containerization Engine: Docker Instead of installing applications directly on our host, we\u0026rsquo;ll use Docker to keep the system clean and make management easier.\nInstall Docker Engine The official convenience script is the easiest way to get the latest version.\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh Add User to Docker Group To run docker commands without sudo, add your user to the docker group. The $USER variable automatically uses the currently logged-in user.\nsudo usermod -aG docker $USER After this, log out and log back in for the change to take effect.\nInstall Docker Compose Docker Compose is essential for managing multi-container applications with a simple YAML file.\nsudo apt install docker-compose-plugin -y To verify the installation:\ndocker compose version Conclusion And that\u0026rsquo;s it for Part 1! We\u0026rsquo;ve successfully turned an old piece of hardware into a hardened, modern server running Debian and Docker with a reliable network configuration. We have a solid and secure foundation to build upon.\nIn the next part of the series, we\u0026rsquo;ll deploy our first critical service: a local, network-wide ad-blocking DNS resolver using AdGuard Home. Stay tuned!\n","permalink":"http://localhost:1313/projects/homelab-series-part-1-debian-docker-foundation/","summary":"\u003ch3 id=\"introduction\"\u003eIntroduction\u003c/h3\u003e\n\u003cp\u003eWelcome to the first post in my new homelab series! I\u0026rsquo;ve always been fascinated by self-hosting and DevOps, and I believe the best way to learn is by doing. In this series, I\u0026rsquo;ll document my journey of turning an old, unused laptop into a powerful, efficient, and secure bare-metal server for hosting a variety of network services.\u003c/p\u003e\n\u003cp\u003eThe goal for this first part is to lay a solid foundation. We\u0026rsquo;ll take an old laptop, install a minimal and stable Linux operating system, perform some initial security hardening, and set up Docker as our containerization engine. By the end of this post, we\u0026rsquo;ll have a perfect blank canvas ready for the exciting services we\u0026rsquo;ll deploy in the upcoming parts.\u003c/p\u003e","title":"Part 1: Reviving an Old Laptop with Debian \u0026 Docker"},{"content":"Your Personal Internet Guardian: How to Build a FREE Ad-Blocker in the Cloud! üöÄ Hey everyone! A while back, I wrote a guide on setting up AdGuard Home on Linode. The world of tech moves fast, and it\u0026rsquo;s time for an upgrade! Today, we\u0026rsquo;re going to build our own powerful, network-wide ad-blocker using Amazon Web Services (AWS), and we\u0026rsquo;ll make it secure with our own domain and SSL certificate.\nThink of this as building a digital gatekeeper for your internet. Before any ads, trackers, or malicious sites can reach your devices, our AdGuard Home server will slam the door shut. The best part? This works on your phone, laptop, smart TV‚Äîanything on your network‚Äîwithout installing a single app on them.\nThis guide is for everyone, from seasoned tech wizards to curious beginners. We\u0026rsquo;ll break down every step in simple terms, so grab a coffee, and let\u0026rsquo;s build something awesome!\n## Chapter 1: Building Our Home in the AWS Cloud ‚òÅÔ∏è First, we need a server. We\u0026rsquo;ll use an Amazon EC2 instance, which is just a fancy name for a virtual computer that you rent.\nSign Up for AWS: If you don\u0026rsquo;t have an account, head to the AWS website and sign up. You\u0026rsquo;ll need a credit card for verification, but for this guide, we can often stay within the Free Tier.\nLaunch Your EC2 Instance:\nLog in to your AWS Console and search for EC2. Click \u0026ldquo;Launch instance\u0026rdquo;. Name: Give your server a cool name, like AdGuard-Server. Application and OS Images: In the search bar, type Debian and select the latest version (e.g., Debian 12). Make sure it\u0026rsquo;s marked \u0026ldquo;Free tier eligible\u0026rdquo;. Instance Type: Choose t2.micro. This is your free, trusty little server. Key Pair (for login): This is your digital key to the server\u0026rsquo;s front door. Click \u0026ldquo;Create a new key pair\u0026rdquo;, name it something like my-adguard-key, and download the .pem file. Keep this file secret and safe! Network settings (The Firewall): This is crucial. We need to tell our server which doors to open. Click \u0026ldquo;Edit\u0026rdquo;. Check the box for \u0026ldquo;Allow SSH traffic from\u0026rdquo; and select My IP. This lets you securely log in. Check \u0026ldquo;Allow HTTPS traffic from the internet\u0026rdquo; and \u0026ldquo;Allow HTTP traffic from the internet\u0026rdquo;. We\u0026rsquo;ll need these for our secure dashboard later. Launch It! Hit the \u0026ldquo;Launch instance\u0026rdquo; button and watch as your new cloud server comes to life.\nGive Your Server a Permanent Address (Elastic IP):\nBy default, your server\u0026rsquo;s public IP address will change every time it reboots. Let\u0026rsquo;s make it permanent! In the EC2 menu on the left, go to \u0026ldquo;Elastic IPs\u0026rdquo;. Click \u0026ldquo;Allocate Elastic IP address\u0026rdquo; and then \u0026ldquo;Allocate\u0026rdquo;. Select the new IP address from the list, click \u0026ldquo;Actions\u0026rdquo;, and then \u0026ldquo;Associate Elastic IP address\u0026rdquo;. Choose your AdGuard-Server instance from the list and click \u0026ldquo;Associate\u0026rdquo;. Your server now has a static IP address that will never change! Make a note of this new IP. ## Chapter 2: Opening the Doors (Configuring the Firewall) üö™ Our server is running, but we need to open a few more specific doors for AdGuard Home to work.\nGo to your EC2 Instance details, click the \u0026ldquo;Security\u0026rdquo; tab, and click on the Security Group name. Click \u0026ldquo;Edit inbound rules\u0026rdquo; and \u0026ldquo;Add rule\u0026rdquo; for each of the following: Port 3000: Custom TCP, Port 3000, Source My IP. (For the initial setup). Port 53 (TCP): Custom TCP, Port 53, Source Anywhere-IPv4. (For DNS). Port 53 (UDP): Custom UDP, Port 53, Source Anywhere-IPv4. (Also for DNS). Port 853: Custom TCP, Port 853, Source Anywhere-IPv4. (For DNS-over-TLS). Click \u0026ldquo;Save rules\u0026rdquo;. Your firewall is now ready! ## Chapter 3: Installing AdGuard Home üõ°Ô∏è Now, let\u0026rsquo;s connect to our server and install the magic software.\nConnect via SSH: Open a terminal (PowerShell on Windows, Terminal on Mac/Linux) and use the key you downloaded to connect. Use your new Elastic IP address! # Replace the path and Elastic IP with your own ssh -i \u0026#34;path/to/my-adguard-key.pem\u0026#34; admin@YOUR_ELASTIC_IP Install AdGuard Home: Run this one simple command. It downloads and installs everything for you. curl -s -S -L [https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh](https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh) | sh -s -- -v Run the Setup Wizard: The script will give you a link, like http://YOUR_ELASTIC_IP:3000. Open this in your browser. Follow the on-screen steps to create your admin username and password. ## Chapter 4: Teaching Your Guardian Who to Trust and What to Block With AdGuard Home installed, the next step is to configure its core brain: the DNS servers it gets its answers from and the blocklists it uses to protect your network.\n1. Setting Up Upstream DNS Servers Think of \u0026ldquo;Upstream DNS Servers\u0026rdquo; as the giant, public phonebooks of the internet. When your AdGuard server doesn\u0026rsquo;t know an address (and it\u0026rsquo;s not on a blocklist), it asks one of these upstreams. It\u0026rsquo;s recommended to use a mix of the best encrypted DNS providers for security, privacy, and speed.\nIn the AdGuard dashboard, go to Settings -\u0026gt; DNS settings. In the \u0026ldquo;Upstream DNS servers\u0026rdquo; box, enter the following, one per line:\nhttps://dns.quad9.net/dns-query https://dns.google/dns-query https://dns.cloudflare.com/dns-query Quad9: Focuses heavily on security, blocking malicious domains. Google: Known for being very fast. Cloudflare: A great all-around choice with a strong focus on privacy. 2. Optimizing DNS Performance Still in the DNS settings page, scroll down to optimize how your server queries the upstreams.\nParallel requests: Select this option. This is the fastest and most resilient mode. It sends your DNS query to all three of your upstream servers at the same time and uses the answer from the very first one that responds. This ensures you always get the quickest possible result.\nEnable EDNS client subnet (ECS): Check this box. This is very important for services like Netflix, YouTube, and other content delivery networks (CDNs). It helps them give you content from a server that is geographically closest to you, resulting in faster speeds and a better experience.\n3. Enabling DNSSEC Right below the upstream servers, there\u0026rsquo;s a checkbox for \u0026ldquo;Enable DNSSEC\u0026rdquo;. You should check this box. DNSSEC is like a digital wax seal on a letter; it verifies that the DNS answers you\u0026rsquo;re getting are authentic and haven\u0026rsquo;t been tampered with. It\u0026rsquo;s a simple, one-click security boost.\n4. Choosing Your Blocklists This is the fun part‚Äîthe actual ad-blocking! Go to Filters -\u0026gt; DNS blocklists. For a \u0026ldquo;Balanced \u0026amp; Powerful\u0026rdquo; setup that blocks aggressively without a high risk of breaking websites, enable the following lists:\nAdGuard DNS filter: A great, well-maintained baseline. OISD Blocklist Big: Widely considered one of the best all-in-one lists for blocking ads, trackers, and malware. HaGeZi\u0026rsquo;s Pro Blocklist: A fantastic list that adds another layer of aggressive blocking for privacy. HaGeZi\u0026rsquo;s Threat Intelligence Feed: A crucial security-only list that focuses on protecting against active threats like phishing and malware. This combination will give you robust protection against both annoyances and real dangers.\n## Chapter 5: Giving Your Server a Name (Free Domain with No-IP) üìõ An IP address is hard to remember. Let\u0026rsquo;s get a free, memorable name for our server.\nSign Up at No-IP: Go to No-IP.com, create a free account, and create a hostname (e.g., my-dns.ddns.net). Point it to Your Server: When creating the hostname, enter your server\u0026rsquo;s permanent Elastic IP address. Confirm your account via email. ## Chapter 6: Making It Secure with SSL/TLS üîê We\u0026rsquo;ll use Let\u0026rsquo;s Encrypt and Certbot to get a free SSL certificate, which lets us use secure https:// and encrypted DNS.\nInstall Certbot: In your SSH session, run these commands:\nsudo apt update sudo apt install certbot -y Get the Certificate: Run this command, replacing the email and domain with your own.\n# This command will temporarily stop any service on port 80, get the certificate, and then finish. sudo certbot certonly --standalone --agree-tos --email YOUR_EMAIL@example.com -d your-no-ip-hostname.ddns.net If it\u0026rsquo;s successful, it will tell you where your certificate files are saved (usually in /etc/letsencrypt/live/your-no-ip-hostname.ddns.net/).\nConfigure AdGuard Home Encryption:\nGo to your AdGuard Home dashboard (Settings -\u0026gt; Encryption settings). Check \u0026ldquo;Enable encryption\u0026rdquo;. In the \u0026ldquo;Server name\u0026rdquo; field, enter your No-IP hostname. Under \u0026ldquo;Certificates\u0026rdquo;, choose \u0026ldquo;Set a certificates file path\u0026rdquo;. Certificate path: /etc/letsencrypt/live/your-no-ip-hostname.ddns.net/fullchain.pem Private key path: /etc/letsencrypt/live/your-no-ip-hostname.ddns.net/privkey.pem Click \u0026ldquo;Save configuration\u0026rdquo;. The page will reload on a secure https:// connection! ## Chapter 7: Automating SSL Renewal (Cron Job Magic) ‚ú® Let\u0026rsquo;s Encrypt certificates last for 90 days. We can tell our server to automatically renew them.\nOpen the Cron Editor: In SSH, run sudo crontab -e and choose nano as your editor. Add the Renewal Job: Add this line to the bottom of the file. It tells the server to try renewing the certificate every day at 2:30 AM. 30 2 * * * systemctl stop AdGuardHome.service \u0026amp;\u0026amp; certbot renew --quiet \u0026amp;\u0026amp; systemctl start AdGuardHome.service Save and exit (Ctrl+X, then Y, then Enter). Your server will now keep its certificate fresh forever! ## Chapter 8: Testing Your New Superpowers (DoH \u0026amp; DoT) üß™ For a direct confirmation, I used these commands on my computer:\nDNS-over-HTTPS (DoH) Test: This test checks if the secure web endpoint for DNS is alive.\ncurl -v [https://your-no-ip-hostname.ddns.net/dns-query](https://your-no-ip-hostname.ddns.net/dns-query) I got a \u0026ldquo;405 Method Not Allowed\u0026rdquo; error, which sounds bad but is actually great news. It means I successfully connected to the server, which correctly told me I didn\u0026rsquo;t send a real query. The connection works!\nDNS-over-TLS (DoT) Test: This checks the dedicated secure port for DNS. I used a tool called kdig.\n# I had to install it first with: sudo apt install knot-dnsutils kdig @your-no-ip-hostname.ddns.net +tls-ca +tls-host=your-no-ip-hostname.ddns.net example.com The command returned a perfect DNS answer for example.com, confirming the secure tunnel was working.\n## Chapter 9: Protecting Your Kingdom (Router \u0026amp; Phone Setup) üè∞ Now, let\u0026rsquo;s point your devices to their new guardian.\nOn Your Home Router: Log in to your router\u0026rsquo;s admin page, find the DNS settings, and enter your server\u0026rsquo;s Elastic IP as the primary DNS server. Leave the secondary field blank! This forces all devices on your Wi-Fi to be protected. Then, restart your router. On Your Mobile Phone: Android: Go to Settings -\u0026gt; Network -\u0026gt; Private DNS. Choose \u0026ldquo;Private DNS provider hostname\u0026rdquo; and enter your No-IP hostname (my-dns.ddns.net). This gives you ad-blocking everywhere, even on cellular data! iOS: You can use a profile to configure DoH. A simple way is to use a site like AdGuard\u0026rsquo;s DNS profile generator, but enter your own server\u0026rsquo;s DoH address (https://my-dns.ddns.net/dns-query). ## Chapter 10: The Ultimate Safety Net (Creating a Snapshot) üì∏ Finally, let\u0026rsquo;s back up our perfect setup.\nIn the EC2 Console, go to your instance details. Click the \u0026ldquo;Storage\u0026rdquo; tab and click the \u0026ldquo;Volume ID\u0026rdquo;. Click \u0026ldquo;Actions\u0026rdquo; -\u0026gt; \u0026ldquo;Create snapshot\u0026rdquo;. Give it a description, like AdGuard-Working-Setup-Backup. If you ever mess something up, you can use this snapshot to restore your server to this exact working state in minutes.\n## Bonus Chapter: Common Troubleshooting Tips If things aren\u0026rsquo;t working, here are a few common pitfalls to check:\nBrowser Overrides Everything: If one device isn\u0026rsquo;t blocking ads, check its browser settings! Modern browsers like Chrome have a \u0026ldquo;Secure DNS\u0026rdquo; feature that can bypass your custom setup. You may need to turn this off. Check Your Laptop\u0026rsquo;s DNS: Make sure your computer\u0026rsquo;s network settings are set to \u0026ldquo;Obtain DNS automatically\u0026rdquo; so it listens to the router. A manually set DNS on your PC will ignore the router\u0026rsquo;s settings. Beware of IPv6: If you run into trouble on one device, try disabling IPv6 in that device\u0026rsquo;s Wi-Fi adapter properties to force it to use your working IPv4 setup. ## It‚Äôs a Wrap! And there you have it! You\u0026rsquo;ve successfully built a personal, secure, ad-blocking DNS server in the cloud. You\u0026rsquo;ve learned about cloud computing, firewalls, DNS, SSL, and automation. Go enjoy a faster, cleaner, and more private internet experience.\n","permalink":"http://localhost:1313/projects/adguard-updated/","summary":"\u003ch1 id=\"your-personal-internet-guardian-how-to-build-a-free-ad-blocker-in-the-cloud-\"\u003eYour Personal Internet Guardian: How to Build a FREE Ad-Blocker in the Cloud! üöÄ\u003c/h1\u003e\n\u003cp\u003eHey everyone! A while back, I wrote a guide on setting up AdGuard Home on Linode. The world of tech moves fast, and it\u0026rsquo;s time for an upgrade! Today, we\u0026rsquo;re going to build our own powerful, network-wide ad-blocker using \u003cstrong\u003eAmazon Web Services (AWS)\u003c/strong\u003e, and we\u0026rsquo;ll make it secure with our own domain and SSL certificate.\u003c/p\u003e\n\u003cp\u003eThink of this as building a digital gatekeeper for your internet. Before any ads, trackers, or malicious sites can reach your devices, our AdGuard Home server will slam the door shut. The best part? This works on your phone, laptop, smart TV‚Äîanything on your network‚Äîwithout installing a single app on them.\u003c/p\u003e","title":"How I Built My Own Ad-Blocking DNS Server in the Cloud (2025 Updated Edition!)"},{"content":"New Project Alert: Running a Powerful AI Locally with Docker! Hey everyone, Prajwol here.\nI\u0026rsquo;ve always been fascinated by the incredible advancements in AI and large language models. While cloud-based models are powerful, I was really curious about what it would take to run a high-performance model right on my own machine. This gives you ultimate privacy, control, and the ability to experiment without limits.\nSo, for my latest project, I decided to dive in and get the DeepSeek-R1 model, a powerful AI, up and running locally using Docker.\nDocker is an amazing tool that lets you package up applications and all their dependencies into a neat little box called a container. This means you can run complex software without the headache of complicated installations or conflicts with other programs on your system. It was the perfect way to tame this powerful AI and get it running smoothly on my Ubuntu machine.\nThe process was a fantastic learning experience, covering everything from setting up Docker to pulling the model and interacting with the AI. It‚Äôs amazing to have that kind of power running on your own hardware.\nI‚Äôve documented my entire process in a detailed, step-by-step guide. If you‚Äôre interested in local AI and want to see how you can run a powerful model yourself, be sure to check it out!\nYou can find the full project guide right here! Let me know what you think of this one!\nPublished: February, 2023\n","permalink":"http://localhost:1313/blog/running-deepseek-r1-on-docker-container-on-ubuntu/","summary":"\u003ch1 id=\"new-project-alert-running-a-powerful-ai-locally-with-docker\"\u003eNew Project Alert: Running a Powerful AI Locally with Docker!\u003c/h1\u003e\n\u003cp\u003eHey everyone, Prajwol here.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;ve always been fascinated by the incredible advancements in AI and large language models. While cloud-based models are powerful, I was really curious about what it would take to run a high-performance model right on my own machine. This gives you ultimate privacy, control, and the ability to experiment without limits.\u003c/p\u003e\n\u003cp\u003eSo, for my latest project, I decided to dive in and get the \u003cstrong\u003eDeepSeek-R1\u003c/strong\u003e model, a powerful AI, up and running locally using \u003cstrong\u003eDocker\u003c/strong\u003e.\u003c/p\u003e","title":"Running a Powerful AI Locally with Docker!"},{"content":"My First Cloud Ad-Blocker: A Look Back at AdGuard Home on Linode Hey everyone, Prajwol here.\nAs I continue to explore different cloud projects, I often think back to the ones that had the biggest impact on my day-to-day life. One of the very first projects that truly changed my internet experience was setting up my own ad-blocking DNS server using AdGuard Home on a Linode instance.\nMy goal was to find a simple, cost-effective way to block ads and trackers across my entire home network. I wanted a \u0026ldquo;set it and forget it\u0026rdquo; solution that would cover every device‚Äîfrom my phone to my smart TV‚Äîwithout needing to install an app on each one. Linode (now Akamai) was the perfect platform for this: straightforward, powerful, and great for hosting a lightweight service like AdGuard Home.\nThe process of spinning up a small server, running a single installation script, and then seeing the query logs light up with blocked requests was incredibly satisfying. It felt like I had taken back a real measure of control over my own network.\nThis project remains a fantastic entry point for anyone wanting to get started with self-hosting and network privacy. I\u0026rsquo;ve kept the original, detailed guide for anyone who wants to follow along.\nYou can find the full step-by-step project guide here! It‚Äôs a rewarding project that delivers tangible results almost immediately. Let me know if you give it a try!\nPublished: Friday, August 22, 2025\n","permalink":"http://localhost:1313/blog/adguard-home-on-cloud/","summary":"\u003ch1 id=\"my-first-cloud-ad-blocker-a-look-back-at-adguard-home-on-linode\"\u003eMy First Cloud Ad-Blocker: A Look Back at AdGuard Home on Linode\u003c/h1\u003e\n\u003cp\u003eHey everyone, Prajwol here.\u003c/p\u003e\n\u003cp\u003eAs I continue to explore different cloud projects, I often think back to the ones that had the biggest impact on my day-to-day life. One of the very first projects that truly changed my internet experience was setting up my own ad-blocking DNS server using AdGuard Home on a Linode instance.\u003c/p\u003e\n\u003cp\u003eMy goal was to find a simple, cost-effective way to block ads and trackers across my entire home network. I wanted a \u0026ldquo;set it and forget it\u0026rdquo; solution that would cover every device‚Äîfrom my phone to my smart TV‚Äîwithout needing to install an app on each one. Linode (now Akamai) was the perfect platform for this: straightforward, powerful, and great for hosting a lightweight service like AdGuard Home.\u003c/p\u003e","title":"My First Cloud Ad-Blocker - A Look Back at AdGuard Home on Linode"},{"content":"What\u0026rsquo;s the buzz about AdGuard Home? Imagine AdGuard Home as your personal internet guardian. This versatile tool blocks ads, trackers, and other online nuisances across all devices connected to your network. Whether you\u0026rsquo;re browsing on your phone, tablet, or computer, AdGuard Home has your back.\nIn today\u0026rsquo;s digital landscape, robust security measures are paramount. Protecting each device shields your family from accidental clicks and malicious attacks, ensuring peace of mind and a secure online environment.\nWhy on the Cloud? While setting up AdGuard Home on your home network is great, installing it on a cloud server like Linode takes things up a notch. Here\u0026rsquo;s why:\nOn-the-Go Protection: Your devices stay protected from ads and trackers, no matter where you are, you can even share it with your family. Centralized Control: Manage and customize your ad-blocking settings from a single dashboard. Enhanced Privacy: Keep your browsing data away from prying eyes. Ready to embark on this ad-free adventure? Let\u0026rsquo;s get started!\nSetting Up The Environment Step 1: Create a Linode Cloud Account Why choose Linode? Through NetworkChuck\u0026rsquo;s referral link, you receive a generous $100 cloud credit - a fantastic start!\nSign Up: Navigate to Linode\u0026rsquo;s signup page and register. Access the Dashboard: Log in and select \u0026lsquo;Linodes\u0026rsquo; from the left-side menu. Create a Linode: Click \u0026lsquo;Create Linode,\u0026rsquo; choose your preferred region, and select an operating system (Debian 11 is a solid choice). Choose a Plan: The Shared 1GB Nanode instance is sufficient for AdGuard Home. Label and Secure: Assign a label to your Linode and set a strong root password. Deploy: Click \u0026lsquo;Create Linode\u0026rsquo; and wait for it to initialize. Once your Linode is up and running, access it via the LISH Console or SSH. (use root as localhost login)\nStep 2: Installing AdGuard Home on Linode Yes, we\u0026rsquo;re already into setting up at this point.\nLog In: Access your Linode using SSH or the LISH Console with your root credentials. Update the system: sudo apt update \u0026amp;\u0026amp; apt upgrade -y Go ahead and copy this command to Install Adguard Home: curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v AdGuard Home is installed and running. You can use CTRL+Shift+V to paste into the terminal.\nStep 3: Configure AdGuard Home Post-installation, you\u0026rsquo;ll see a list of IP addresses with port :3000. Access the Web Interface: Open your browser and navigate to the IP address followed by :3000. If you encounter a security warning, proceed by clicking \u0026ldquo;Continue to site.\u0026rdquo; Initial Setup: Click \u0026lsquo;Get Started\u0026rsquo; and follow the prompts. When uncertain, default settings are typically fine. Set Credentials: Set up the Username and Password. Step 4: Integrate AdGuard Home with Your Router After this, your AdGuard Home is running, but in order to use it on your devices you need to set up inside your home router for all your devices to be protected. For that, I can\u0026rsquo;t walk you through each and every router\u0026rsquo;s settings, but the steps are pretty similar.\nFind your router IP address, you should be able to find it on the back of your router (commonly 192.168.0.1 or 192.169.1.1) enter it into your browser. Login into your router using the credentials mentioned in the back of your router; the default is often admin for both username and password. I suggest you change your default password. Configure DNS Settings: Enable DHCP Server: Ensure your router\u0026rsquo;s DHCP server is active. Set DNS Addresses: Input your AdGuard Home server\u0026rsquo;s IP as the primary DNS (mine was 96.126.113.207). For secondary DNS, options like 1.1.1.1 (Cloudflare), 9.9.9.9 (Quad9), or 8.8.8.8 (Google) are reliable. Save and apply the changes. Fine-Tuning AdGuard Home If you\u0026rsquo;ve done everything till here you should be good, but for those who enjoy customizations, AdGuard Home offers a plethora of settings. Some of the customization I did are:\nSettings Go to Settings -\u0026gt; General Settings: You can enable Parental Control and Safe Search. You can also make your Statistics last longer than 24hrs which is default. Now on Settings -\u0026gt; DNS Settings By default, it uses DNS from quad9 which is pretty good but I suggest you add more. You can click on the list of known DNS providers, which you can choose from. I used: https://dns.quad9.net/dns-query https://dns.google/dns-query https://dns.cloudflare.com/dns-query Enable \u0026lsquo;Load Balancing\u0026rsquo; to distribute queries evenly. Scroll down to \u0026lsquo;DNS server configuration\u0026rsquo; and enable DNSSEC for enhanced security. Click on Save. Filters DNS blocklists Go to Filters -\u0026gt; DNS blocklists, here you can add a blocklist that people have created and use it to block even more things. By default, AdGuard uses the AdGuard DNS filter, and you can add more.\nClick on Add blocklist -\u0026gt; Choose from the list Don\u0026rsquo;t choose too many from the list cause it may slow your internet requests. These are the blocklists I added. And just like that you are blocking more and more things. DNS rewrites Go to Filters -\u0026gt; DNS rewrites, here you can add your own DNS entries, so I added AdGuard here.\nClick on Add DNS rewrite Type in domain adguardforme.local and your IP address for AdGuard Home. And save it. Now, when I want to go on the AdGuard Home dashboard I just type in adguardforme.local and I\u0026rsquo;m into AdGuard, I don\u0026rsquo;t have to remember the IP address.\nCustom filtering rules Go to Filters -\u0026gt; Custom filtering rules. For some reason when I use Facebook on mobile device stories and videos did not load up, so I added custom filtering rules.\n@@||graph.facebook.com^$important ","permalink":"http://localhost:1313/projects/adguard-home-on-cloud/","summary":"\u003ch1 id=\"whats-the-buzz-about-adguard-home\"\u003eWhat\u0026rsquo;s the buzz about AdGuard Home?\u003c/h1\u003e\n\u003cp\u003eImagine AdGuard Home as your personal internet guardian. This versatile tool blocks ads, trackers, and other online nuisances across all devices connected to your network. Whether you\u0026rsquo;re browsing on your phone, tablet, or computer, AdGuard Home has your back.\u003c/p\u003e\n\u003cp\u003eIn today\u0026rsquo;s digital landscape, robust security measures are paramount. Protecting each device shields your family from accidental clicks and malicious attacks, ensuring peace of mind and a secure online environment.\u003c/p\u003e","title":"Running Private Adguard Server on Cloud (Linode)"},{"content":"What\u0026rsquo;s a Docker Container? Before we dive into setting up DeepSeek-R1, let me explain what a Docker container is. Imagine you have a toy that works perfectly on your birthday but gets broken if you move it to another room. A Docker container is like a magic box that keeps your AI model (the toy) in perfect condition wherever you take it, whether it\u0026rsquo;s running as a background task, on a web server, or even in the cloud.\nDocker containers encapsulate everything required to run an application: the code, dependencies, and environment settings. This ensures consistency across different machines, which is super important for AI models that rely on precise configurations.\nSetting Up The Environment Step 1: Install Ubuntu on Windows (If You Haven\u0026rsquo;t Already) If you\u0026rsquo;re using Windows, the easiest way to get an Ubuntu environment is through the Microsoft Store. Here\u0026rsquo;s how:\nOpen the Microsoft Store and search for Ubuntu. Click Get and let it install. Once installed, open Ubuntu from the Start menu and follow the setup instructions. Update the system: sudo apt update \u0026amp;\u0026amp; sudo apt upgrade Now, you have an Ubuntu terminal running on Windows!\nStep 2: Install Docker (If You Haven\u0026rsquo;t Already) First, let\u0026rsquo;s check if you have Docker installed. Open a terminal and run:\ndocker --version If that returns a version number, congrats! If not, install Docker:\nsudo apt update \u0026amp;\u0026amp; sudo apt install docker.io -y sudo systemctl enable --now docker Step 3: Prerequisites for NVIDIA GPU Install NVIDIA Container Toolkit:\nConfiguring the production repository: curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed \u0026#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g\u0026#39; | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list Update the package list: sudo apt-get update Install the NVIDIA Container Toolkit: sudo apt-get install -y nvidia-container-toolkit Running Ollama Inside Docker Run these commands(P.S. shoutout to NetworkChuck):\ndocker run -d \\ --gpus all \\ -v ollama:/root/.ollama \\ -p 11434:11434 \\ --security-opt=no-new-privileges \\ --cap-drop=ALL \\ --cap-add=SYS_NICE \\ --memory=8g \\ --memory-swap=8g \\ --cpus=4 \\ --read-only \\ --name ollama \\ ollama/ollama Running DeepSeek-R1 Locally Time to bring DeepSeek-R1 to life locally and containerized:\ndocker exec -it ollama ollama run deepseek-r1 or you can run other versions of deepseek-r1 just by typing in the version at the end after a colon(:)\ndocker exec -it ollama ollama run deepseek-r1:7b After this, play around with the AI, if you wanna exit just type:\n/bye Starting Deepseek-R1 To Start Deepseek-R1 from next time go to Ubuntu and type:\ndocker start ollama this will start ollama docker container; then type:\ndocker exec -it ollama ollama run deepseek-r1:7b ","permalink":"http://localhost:1313/projects/running-deepseek-r1-on-docker-container-on-ubuntu/","summary":"\u003ch1 id=\"whats-a-docker-container\"\u003eWhat\u0026rsquo;s a Docker Container?\u003c/h1\u003e\n\u003cp\u003eBefore we dive into setting up DeepSeek-R1, let me explain what a Docker container is. Imagine you have a toy that works perfectly on your birthday but gets broken if you move it to another room. A Docker container is like a magic box that keeps your AI model (the toy) in perfect condition wherever you take it, whether it\u0026rsquo;s running as a background task, on a web server, or even in the cloud.\u003c/p\u003e","title":"Dive into AI Fun: Running DeepSeek-R1 on a Docker Container on Ubuntu"},{"content":"Description I joined AbbVie initially as a contractor and quickly demonstrated the skills and dedication that led to my conversion to a full-time position. In my role, I stepped into a high-stakes production environment where precision and operational stability are paramount. My work centered on the optimization and maintenance of sophisticated, machine learning-based visual inspection systems. I was responsible for fine-tuning these models, analyzing their performance data, and troubleshooting complex technical issues across both hardware and software, including the POM and PCE systems.\nThis wasn\u0026rsquo;t just about keeping machines running; it was about enhancing them. By applying a systematic, data-driven approach, I contributed to a 30% reduction in product waste, a metric that translates directly to improved efficiency and sustainability. Working within strict GMPs and utilizing systems like SAP for material tracking, I learned to balance technical problem-solving with rigorous compliance, ensuring that every action contributed to the stability and reliability of mission-critical operations.\n","permalink":"http://localhost:1313/experience/abbvie/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eI joined AbbVie initially as a contractor and quickly demonstrated the skills and dedication that led to my conversion to a full-time position. In my role, I stepped into a high-stakes production environment where precision and operational stability are paramount. My work centered on the optimization and maintenance of sophisticated, machine learning-based visual inspection systems. I was responsible for fine-tuning these models, analyzing their performance data, and troubleshooting complex technical issues across both hardware and software, including the POM and PCE systems.\u003c/p\u003e","title":"Operator III"},{"content":"Description As my first professional role after moving to the United States, my position at FedEx was a crucial step in adapting my technical skills to a new corporate environment. My journey began as a contractor, where my performance and analytical skills in a fast-paced setting led to my transition to a full-time Associate role. At the device testing center, I was on the front lines of quality assurance for a wide array of consumer electronics. I conducted comprehensive, systematic testing on mobile devices, smartwatches, and routers, executing detailed test plans to identify hardware vulnerabilities, software bugs, and non-compliance with network standards.\nMy responsibilities included meticulously documenting my findings, reproducing bugs to assist developers, and providing clear, actionable reports to engineering teams. This collaborative process was crucial in accelerating the repair cycle and ensuring that products met the highest standards of quality and security before reaching the market. The role sharpened my analytical skills and gave me a deep appreciation for the importance of rigorous testing in the software development lifecycle.\n","permalink":"http://localhost:1313/experience/fedex/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eAs my first professional role after moving to the United States, my position at FedEx was a crucial step in adapting my technical skills to a new corporate environment. My journey began as a contractor, where my performance and analytical skills in a fast-paced setting led to my transition to a full-time Associate role. At the device testing center, I was on the front lines of quality assurance for a wide array of consumer electronics. I conducted comprehensive, systematic testing on mobile devices, smartwatches, and routers, executing detailed test plans to identify hardware vulnerabilities, software bugs, and non-compliance with network standards.\u003c/p\u003e","title":"Product Testing Associate"},{"content":"Description As the IT Support Specialist for a bustling international college with over 2,500 students and staff, I was at the heart of the campus\u0026rsquo;s technical operations. My role was dynamic and comprehensive, involving end-to-end technical support across a diverse, multi-building campus. I managed the entire user lifecycle, from onboarding new accounts to ensuring smooth system setups across Windows, Linux, and Mac environments. I was the primary point of contact for all technical challenges, resolving Tier 1 and 2 support tickets with a 90% SLA adherence and troubleshooting complex OS issues to minimize downtime.\nMy tenure was marked by significant growth and adaptation. I led the complete technical setup of eight new computer labs, managing everything from hardware deployment and network cabling to software installation and configuration. When the COVID-19 pandemic hit, I was instrumental in transitioning the campus to a hybrid learning model, my first professional experience navigating such a large-scale shift. This required rapidly scaling our remote support capabilities and ensuring both students and faculty could operate effectively from anywhere.\nA cornerstone project of my time was the complete technical overhaul of the newly acquired Kumari Film Hall. I was deeply involved in the project to transform the old cinema into modern lecture halls, which included designing and deploying the entire network infrastructure, setting up AV systems, and ensuring seamless integration with the main campus network.\nTo support these expanding operations, I took the lead in deploying a new UVDesk help desk ticketing system on a CentOS server and embraced automation, utilizing tools like OK Goldy to streamline user creation in Google Workspace. These initiatives standardized processes, improved efficiency, and allowed our team to successfully manage the college\u0026rsquo;s ambitious growth.\n","permalink":"http://localhost:1313/experience/islingtoncollege/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eAs the IT Support Specialist for a bustling international college with over 2,500 students and staff, I was at the heart of the campus\u0026rsquo;s technical operations. My role was dynamic and comprehensive, involving end-to-end technical support across a diverse, multi-building campus. I managed the entire user lifecycle, from onboarding new accounts to ensuring smooth system setups across Windows, Linux, and Mac environments. I was the primary point of contact for all technical challenges, resolving Tier 1 and 2 support tickets with a 90% SLA adherence and troubleshooting complex OS issues to minimize downtime.\u003c/p\u003e","title":"IT Support Specialist"},{"content":"Description Building on my foundational experience, my internship at BlackBox Technologies immersed me in a more complex, project-based environment. I was an integral part of a development team tasked with building a web-based attendance system from the ground up. This role provided me with invaluable hands-on, full-stack experience. I contributed to the backend by assisting senior engineers with the development of business logic in .NET, giving me insight into server-side architecture. Simultaneously, I was responsible for building responsive, user-facing components for the front-end using HTML, CSS, and JavaScript.\nThis experience was a deep dive into the software development lifecycle. I learned how to translate business requirements into technical specifications, participated in code reviews, and understood the synergy between front-end and back-end systems. Working in close collaboration with the engineering team on a single, focused product was an excellent opportunity to apply my skills to a real-world project and solidify my understanding of creating robust, scalable web applications.\n","permalink":"http://localhost:1313/experience/blackbox/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eBuilding on my foundational experience, my internship at BlackBox Technologies immersed me in a more complex, project-based environment. I was an integral part of a development team tasked with building a web-based attendance system from the ground up. This role provided me with invaluable hands-on, full-stack experience. I contributed to the backend by assisting senior engineers with the development of business logic in .NET, giving me insight into server-side architecture. Simultaneously, I was responsible for building responsive, user-facing components for the front-end using HTML, CSS, and JavaScript.\u003c/p\u003e","title":"Web Development Intern"},{"content":"Description My journey into professional software development began at Radiant Infotech, my first internship and job in the tech industry. This role was a pivotal transition from academic theory to real-world application. I was entrusted with supporting the full lifecycle of client websites, which provided an immersive learning experience. My primary responsibility was to develop responsive, pixel-perfect front-end interfaces using HTML, CSS, and Bootstrap, translating design files into functional web components. A key part of this process was using Adobe Photoshop to prepare and optimize web graphics, ensuring both aesthetic quality and optimal performance.\nBeyond the initial development, my role extended to managing website content through various CMS platforms and performing rigorous debugging to ensure cross-browser compatibility and a seamless user experience. This foundational internship was crucial in building my confidence and skills in modern web development, teaching me how to collaborate effectively within a team to deliver high-quality digital products for clients.\n","permalink":"http://localhost:1313/experience/radiantinfotech/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eMy journey into professional software development began at Radiant Infotech, my first internship and job in the tech industry. This role was a pivotal transition from academic theory to real-world application. I was entrusted with supporting the full lifecycle of client websites, which provided an immersive learning experience. My primary responsibility was to develop responsive, pixel-perfect front-end interfaces using HTML, CSS, and Bootstrap, translating design files into functional web components. A key part of this process was using Adobe Photoshop to prepare and optimize web graphics, ensuring both aesthetic quality and optimal performance.\u003c/p\u003e","title":"Web Development Intern"},{"content":"Introduction Welcome to my personal portfolio website. I respect your privacy and am committed to protecting it. This policy outlines what information is collected when you visit my site and how that information is used.\nInformation Collection and Use I collect information in two ways: information you provide directly and anonymous data collected by analytics services.\nPersonal Data You Provide When you request a copy of my resume, you are asked to voluntarily provide your email address.\nHow it\u0026rsquo;s collected: This information is collected via an embedded Google Form. Why it\u0026rsquo;s collected: It is used for the sole purpose of sending the requested resume document to you through an automated process managed by Google Apps Script. How it\u0026rsquo;s used: Your email will not be used for marketing purposes, sold, or shared with any third parties. Anonymous Usage Data To improve the user experience and analyze traffic, this website uses the following third-party services:\nCloudflare Web Analytics: This service collects anonymous traffic data such as page views and country of origin. It does not use cookies or collect personally identifiable information. You can view their privacy policy here.\nMicrosoft Clarity: This service helps me understand user behavior through anonymous session recordings and heatmaps. This data is used to improve the website\u0026rsquo;s design and functionality. You can view their privacy policy here.\nService Providers This website relies on the following third-party service providers to function:\nGoogle Workspace (Forms, Sheets, Apps Script): Used to manage and automate resume requests. Cloudflare \u0026amp; Microsoft: Used for collecting anonymous web analytics. Netlify \u0026amp; GitHub: Used for hosting and deploying the website. Changes to This Privacy Policy I may update this Privacy Policy from time to time. I will notify you of any changes by posting the new Privacy Policy on this page. You are advised to review this page periodically for any changes.\nContact Me If you have any questions about this Privacy Policy, please contact me at: prajwolad18@gmail.com\n","permalink":"http://localhost:1313/privacy-policy/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWelcome to my personal portfolio website. I respect your privacy and am committed to protecting it. This policy outlines what information is collected when you visit my site and how that information is used.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"information-collection-and-use\"\u003eInformation Collection and Use\u003c/h2\u003e\n\u003cp\u003eI collect information in two ways: information you provide directly and anonymous data collected by analytics services.\u003c/p\u003e\n\u003ch3 id=\"personal-data-you-provide\"\u003ePersonal Data You Provide\u003c/h3\u003e\n\u003cp\u003eWhen you request a copy of my resume, you are asked to voluntarily provide your email address.\u003c/p\u003e","title":"Privacy Policy"},{"content":"My New Weekend Project: Building a Personal Ad-Blocking Server in the Cloud! Hey everyone, Prajwol here.\nLike a lot of you, I spend a good chunk of my day online. And lately, it\u0026rsquo;s felt like I\u0026rsquo;m in a constant battle with pop-ups, trackers, and auto-playing video ads. I\u0026rsquo;ve used browser extensions for years, but I wanted a more powerful solution‚Äîsomething that would protect my entire home network, including my phone and smart TV, without needing to install software everywhere.\nSo, I decided to take on a new project: building my very own ad-blocking DNS server in the cloud.\nI\u0026rsquo;d done something similar a while back with Linode, but this time I wanted to dive into the world of Amazon Web Services (AWS) and see if I could build a reliable, secure, and cost-effective setup from scratch. It turned into quite the adventure, involving a late-night session of launching a virtual server, wrestling with firewalls, and securing my own private domain with an SSL certificate.\nThe end result? It\u0026rsquo;s been fantastic. My web pages load noticeably faster, and the general online experience feels so much cleaner and less intrusive. Plus, knowing that I have full control over my own corner of the internet is incredibly satisfying. It\u0026rsquo;s a great feeling to see the query logs fill up with blocked requests for domains I\u0026rsquo;ve never even heard of!\nI documented every single step of my journey, from the first click in the AWS console to the final configuration on my home router. If you\u0026rsquo;re curious about how to build one for yourself, I\u0026rsquo;ve written up a complete, step-by-step guide.\nYou can check out the full project guide here! It was a challenging but really rewarding project. Let me know what you think!\nPublished: Friday, August 22, 2025\n","permalink":"http://localhost:1313/blog/adguard-aws/","summary":"\u003ch1 id=\"my-new-weekend-project-building-a-personal-ad-blocking-server-in-the-cloud\"\u003eMy New Weekend Project: Building a Personal Ad-Blocking Server in the Cloud!\u003c/h1\u003e\n\u003cp\u003eHey everyone, Prajwol here.\u003c/p\u003e\n\u003cp\u003eLike a lot of you, I spend a good chunk of my day online. And lately, it\u0026rsquo;s felt like I\u0026rsquo;m in a constant battle with pop-ups, trackers, and auto-playing video ads. I\u0026rsquo;ve used browser extensions for years, but I wanted a more powerful solution‚Äîsomething that would protect my entire home network, including my phone and smart TV, without needing to install software everywhere.\u003c/p\u003e","title":"Building a Personal Ad-Blocking Server in the Cloud!"},{"content":"Introduction Welcome to the first post in my new homelab series! I\u0026rsquo;ve always been fascinated by self-hosting and DevOps, and I believe the best way to learn is by doing. In this series, I\u0026rsquo;ll document my journey of turning an old, unused laptop into a powerful, efficient, and secure bare-metal server for hosting a variety of network services.\nThe goal for this first part is to lay a solid foundation. We\u0026rsquo;ll take an old laptop, install a minimal and stable Linux operating system, perform some initial security hardening, and set up Docker as our containerization engine. By the end of this post, we\u0026rsquo;ll have a perfect blank canvas ready for the exciting services we\u0026rsquo;ll deploy in the upcoming parts.\n1. Choosing the Hardware \u0026amp; OS Why an Old Laptop? Before diving in, why use an old laptop instead of a Raspberry Pi or a dedicated server? For a starter homelab, a laptop has three huge advantages:\nCost-Effective: It\u0026rsquo;s free if you have one lying around! Built-in UPS: The battery acts as a built-in Uninterruptible Power Supply (UPS), keeping the server running through short power outages. Low Power Consumption: Laptop hardware is designed to be power-efficient, which is great for a device that will be running 24/7. Why Debian 13 \u0026ldquo;Trixie\u0026rdquo;? For the operating system, I chose Debian. It\u0026rsquo;s renowned for its stability, security, and massive package repository. It‚Äôs the bedrock of many other distributions (like Ubuntu) and is perfect for a server because it\u0026rsquo;s lightweight and doesn\u0026rsquo;t include unnecessary software. We\u0026rsquo;ll be using the minimal \u0026ldquo;net-install\u0026rdquo; to ensure we only install what we absolutely need.\n2. Installation and Network Configuration The installation process is straightforward, but the network setup is key to a reliable server.\nMinimal Installation Create a Bootable USB: I downloaded the Debian 13 \u0026ldquo;netinst\u0026rdquo; ISO from the official website and used Rufus on Windows to create a bootable USB drive. Boot from USB: I plugged the USB into the laptop and booted from it (usually pressing F12, F2, or Esc during startup to select the USB device). Language, Location, and Keyboard: Selected English, United States, and the default keyboard layout. Network Setup: Connected the laptop to my home network (Ethernet preferred for stability). Hostname \u0026amp; Domain: Entered a short, memorable hostname for the server (e.g., homelab) and left the domain blank. User Accounts: Set a root password. Created a non-root regular user (this will be used for daily management). Partition Disks: Chose Guided ‚Äì use entire disk with separate /home partition. This is simpler for a server setup. Software Selection: At the ‚ÄúSoftware selection‚Äù screen: Unchecked ‚ÄúDebian desktop environment‚Äù Checked ‚ÄúSSH server‚Äù and ‚Äústandard system utilities‚Äù This ensures a clean command-line system that can be accessed remotely. GRUB Bootloader: Installed GRUB on the primary drive (so the system boots correctly). Finish Installation: Removed the USB drive when prompted and rebooted into the fresh Debian install. Setting a Static IP A server needs a permanent, unchanging IP address. The best way to do this is with DHCP Reservation on your router. This tells your router to always assign the same IP address to your server\u0026rsquo;s unique MAC address.\nFirst, find your laptop‚Äôs current IP address and network interface name by running:\nip a You‚Äôll see output similar to:\n2: enp3s0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\rinet 192.168.0.45/24 brd 192.168.0.255 scope global dynamic enp3s0\rvalid_lft 86396sec preferred_lft 86396sec In this example:\nInterface name: enp3s0 Current IP: 192.168.0.45 MAC address: shown under link/ether in the same section. With this info, log into your router‚Äôs admin panel, find the \u0026ldquo;DHCP Reservation\u0026rdquo; or \u0026ldquo;Static Leases\u0026rdquo; section, and assign a memorable IP address (e.g., 192.168.0.45) to your server‚Äôs MAC address.\nThis ensures the server always gets the same IP from your router, making it easy to find on your network.\nConnecting Remotely with SSH With a static IP set, all future management will be done remotely using an SSH client. For Windows, I highly recommend Solar-PuTTY. I created a new session, entered the server\u0026rsquo;s static IP address, my username, and password, and connected.\n3. Initial Server Hardening With a remote SSH session active, the first thing to do is secure the server and configure it for its headless role.\nUpdate the System First, let\u0026rsquo;s make sure all packages are up to date.\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y Configure the Firewall ufw (Uncomplicated Firewall) is perfect for a simple setup. We\u0026rsquo;ll set it to deny all incoming traffic by default and only allow SSH connections.\n# Install UFW sudo apt install ufw -y # Allow SSH connections sudo ufw allow ssh # Enable the firewall sudo ufw enable Configure Lid-Close Action To ensure the laptop keeps running when the lid is closed, we edit the logind.conf file.\nsudo nano /etc/systemd/logind.conf Uncomment the line:\nHandleLidSwitch=ignore Save the file, then restart the service:\nsudo systemctl restart systemd-logind.service 4. Installing the Containerization Engine: Docker Instead of installing applications directly on our host, we\u0026rsquo;ll use Docker to keep the system clean and make management easier.\nInstall Docker Engine The official convenience script is the easiest way to get the latest version.\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh Add User to Docker Group To run docker commands without sudo, add your user to the docker group. The $USER variable automatically uses the currently logged-in user.\nsudo usermod -aG docker $USER After this, log out and log back in for the change to take effect.\nInstall Docker Compose Docker Compose is essential for managing multi-container applications with a simple YAML file.\nsudo apt install docker-compose-plugin -y To verify the installation:\ndocker compose version Conclusion And that\u0026rsquo;s it for Part 1! We\u0026rsquo;ve successfully turned an old piece of hardware into a hardened, modern server running Debian and Docker with a reliable network configuration. We have a solid and secure foundation to build upon.\nIn the next part of the series, we\u0026rsquo;ll deploy our first critical service: a local, network-wide ad-blocking DNS resolver using AdGuard Home. Stay tuned!\n","permalink":"http://localhost:1313/projects/homelab-series-part-1-debian-docker-foundation/","summary":"\u003ch3 id=\"introduction\"\u003eIntroduction\u003c/h3\u003e\n\u003cp\u003eWelcome to the first post in my new homelab series! I\u0026rsquo;ve always been fascinated by self-hosting and DevOps, and I believe the best way to learn is by doing. In this series, I\u0026rsquo;ll document my journey of turning an old, unused laptop into a powerful, efficient, and secure bare-metal server for hosting a variety of network services.\u003c/p\u003e\n\u003cp\u003eThe goal for this first part is to lay a solid foundation. We\u0026rsquo;ll take an old laptop, install a minimal and stable Linux operating system, perform some initial security hardening, and set up Docker as our containerization engine. By the end of this post, we\u0026rsquo;ll have a perfect blank canvas ready for the exciting services we\u0026rsquo;ll deploy in the upcoming parts.\u003c/p\u003e","title":"Part 1: Reviving an Old Laptop with Debian \u0026 Docker"},{"content":"Your Personal Internet Guardian: How to Build a FREE Ad-Blocker in the Cloud! üöÄ Hey everyone! A while back, I wrote a guide on setting up AdGuard Home on Linode. The world of tech moves fast, and it\u0026rsquo;s time for an upgrade! Today, we\u0026rsquo;re going to build our own powerful, network-wide ad-blocker using Amazon Web Services (AWS), and we\u0026rsquo;ll make it secure with our own domain and SSL certificate.\nThink of this as building a digital gatekeeper for your internet. Before any ads, trackers, or malicious sites can reach your devices, our AdGuard Home server will slam the door shut. The best part? This works on your phone, laptop, smart TV‚Äîanything on your network‚Äîwithout installing a single app on them.\nThis guide is for everyone, from seasoned tech wizards to curious beginners. We\u0026rsquo;ll break down every step in simple terms, so grab a coffee, and let\u0026rsquo;s build something awesome!\n## Chapter 1: Building Our Home in the AWS Cloud ‚òÅÔ∏è First, we need a server. We\u0026rsquo;ll use an Amazon EC2 instance, which is just a fancy name for a virtual computer that you rent.\nSign Up for AWS: If you don\u0026rsquo;t have an account, head to the AWS website and sign up. You\u0026rsquo;ll need a credit card for verification, but for this guide, we can often stay within the Free Tier.\nLaunch Your EC2 Instance:\nLog in to your AWS Console and search for EC2. Click \u0026ldquo;Launch instance\u0026rdquo;. Name: Give your server a cool name, like AdGuard-Server. Application and OS Images: In the search bar, type Debian and select the latest version (e.g., Debian 12). Make sure it\u0026rsquo;s marked \u0026ldquo;Free tier eligible\u0026rdquo;. Instance Type: Choose t2.micro. This is your free, trusty little server. Key Pair (for login): This is your digital key to the server\u0026rsquo;s front door. Click \u0026ldquo;Create a new key pair\u0026rdquo;, name it something like my-adguard-key, and download the .pem file. Keep this file secret and safe! Network settings (The Firewall): This is crucial. We need to tell our server which doors to open. Click \u0026ldquo;Edit\u0026rdquo;. Check the box for \u0026ldquo;Allow SSH traffic from\u0026rdquo; and select My IP. This lets you securely log in. Check \u0026ldquo;Allow HTTPS traffic from the internet\u0026rdquo; and \u0026ldquo;Allow HTTP traffic from the internet\u0026rdquo;. We\u0026rsquo;ll need these for our secure dashboard later. Launch It! Hit the \u0026ldquo;Launch instance\u0026rdquo; button and watch as your new cloud server comes to life.\nGive Your Server a Permanent Address (Elastic IP):\nBy default, your server\u0026rsquo;s public IP address will change every time it reboots. Let\u0026rsquo;s make it permanent! In the EC2 menu on the left, go to \u0026ldquo;Elastic IPs\u0026rdquo;. Click \u0026ldquo;Allocate Elastic IP address\u0026rdquo; and then \u0026ldquo;Allocate\u0026rdquo;. Select the new IP address from the list, click \u0026ldquo;Actions\u0026rdquo;, and then \u0026ldquo;Associate Elastic IP address\u0026rdquo;. Choose your AdGuard-Server instance from the list and click \u0026ldquo;Associate\u0026rdquo;. Your server now has a static IP address that will never change! Make a note of this new IP. ## Chapter 2: Opening the Doors (Configuring the Firewall) üö™ Our server is running, but we need to open a few more specific doors for AdGuard Home to work.\nGo to your EC2 Instance details, click the \u0026ldquo;Security\u0026rdquo; tab, and click on the Security Group name. Click \u0026ldquo;Edit inbound rules\u0026rdquo; and \u0026ldquo;Add rule\u0026rdquo; for each of the following: Port 3000: Custom TCP, Port 3000, Source My IP. (For the initial setup). Port 53 (TCP): Custom TCP, Port 53, Source Anywhere-IPv4. (For DNS). Port 53 (UDP): Custom UDP, Port 53, Source Anywhere-IPv4. (Also for DNS). Port 853: Custom TCP, Port 853, Source Anywhere-IPv4. (For DNS-over-TLS). Click \u0026ldquo;Save rules\u0026rdquo;. Your firewall is now ready! ## Chapter 3: Installing AdGuard Home üõ°Ô∏è Now, let\u0026rsquo;s connect to our server and install the magic software.\nConnect via SSH: Open a terminal (PowerShell on Windows, Terminal on Mac/Linux) and use the key you downloaded to connect. Use your new Elastic IP address! # Replace the path and Elastic IP with your own ssh -i \u0026#34;path/to/my-adguard-key.pem\u0026#34; admin@YOUR_ELASTIC_IP Install AdGuard Home: Run this one simple command. It downloads and installs everything for you. curl -s -S -L [https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh](https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh) | sh -s -- -v Run the Setup Wizard: The script will give you a link, like http://YOUR_ELASTIC_IP:3000. Open this in your browser. Follow the on-screen steps to create your admin username and password. ## Chapter 4: Teaching Your Guardian Who to Trust and What to Block With AdGuard Home installed, the next step is to configure its core brain: the DNS servers it gets its answers from and the blocklists it uses to protect your network.\n1. Setting Up Upstream DNS Servers Think of \u0026ldquo;Upstream DNS Servers\u0026rdquo; as the giant, public phonebooks of the internet. When your AdGuard server doesn\u0026rsquo;t know an address (and it\u0026rsquo;s not on a blocklist), it asks one of these upstreams. It\u0026rsquo;s recommended to use a mix of the best encrypted DNS providers for security, privacy, and speed.\nIn the AdGuard dashboard, go to Settings -\u0026gt; DNS settings. In the \u0026ldquo;Upstream DNS servers\u0026rdquo; box, enter the following, one per line:\nhttps://dns.quad9.net/dns-query https://dns.google/dns-query https://dns.cloudflare.com/dns-query Quad9: Focuses heavily on security, blocking malicious domains. Google: Known for being very fast. Cloudflare: A great all-around choice with a strong focus on privacy. 2. Optimizing DNS Performance Still in the DNS settings page, scroll down to optimize how your server queries the upstreams.\nParallel requests: Select this option. This is the fastest and most resilient mode. It sends your DNS query to all three of your upstream servers at the same time and uses the answer from the very first one that responds. This ensures you always get the quickest possible result.\nEnable EDNS client subnet (ECS): Check this box. This is very important for services like Netflix, YouTube, and other content delivery networks (CDNs). It helps them give you content from a server that is geographically closest to you, resulting in faster speeds and a better experience.\n3. Enabling DNSSEC Right below the upstream servers, there\u0026rsquo;s a checkbox for \u0026ldquo;Enable DNSSEC\u0026rdquo;. You should check this box. DNSSEC is like a digital wax seal on a letter; it verifies that the DNS answers you\u0026rsquo;re getting are authentic and haven\u0026rsquo;t been tampered with. It\u0026rsquo;s a simple, one-click security boost.\n4. Choosing Your Blocklists This is the fun part‚Äîthe actual ad-blocking! Go to Filters -\u0026gt; DNS blocklists. For a \u0026ldquo;Balanced \u0026amp; Powerful\u0026rdquo; setup that blocks aggressively without a high risk of breaking websites, enable the following lists:\nAdGuard DNS filter: A great, well-maintained baseline. OISD Blocklist Big: Widely considered one of the best all-in-one lists for blocking ads, trackers, and malware. HaGeZi\u0026rsquo;s Pro Blocklist: A fantastic list that adds another layer of aggressive blocking for privacy. HaGeZi\u0026rsquo;s Threat Intelligence Feed: A crucial security-only list that focuses on protecting against active threats like phishing and malware. This combination will give you robust protection against both annoyances and real dangers.\n## Chapter 5: Giving Your Server a Name (Free Domain with No-IP) üìõ An IP address is hard to remember. Let\u0026rsquo;s get a free, memorable name for our server.\nSign Up at No-IP: Go to No-IP.com, create a free account, and create a hostname (e.g., my-dns.ddns.net). Point it to Your Server: When creating the hostname, enter your server\u0026rsquo;s permanent Elastic IP address. Confirm your account via email. ## Chapter 6: Making It Secure with SSL/TLS üîê We\u0026rsquo;ll use Let\u0026rsquo;s Encrypt and Certbot to get a free SSL certificate, which lets us use secure https:// and encrypted DNS.\nInstall Certbot: In your SSH session, run these commands:\nsudo apt update sudo apt install certbot -y Get the Certificate: Run this command, replacing the email and domain with your own.\n# This command will temporarily stop any service on port 80, get the certificate, and then finish. sudo certbot certonly --standalone --agree-tos --email YOUR_EMAIL@example.com -d your-no-ip-hostname.ddns.net If it\u0026rsquo;s successful, it will tell you where your certificate files are saved (usually in /etc/letsencrypt/live/your-no-ip-hostname.ddns.net/).\nConfigure AdGuard Home Encryption:\nGo to your AdGuard Home dashboard (Settings -\u0026gt; Encryption settings). Check \u0026ldquo;Enable encryption\u0026rdquo;. In the \u0026ldquo;Server name\u0026rdquo; field, enter your No-IP hostname. Under \u0026ldquo;Certificates\u0026rdquo;, choose \u0026ldquo;Set a certificates file path\u0026rdquo;. Certificate path: /etc/letsencrypt/live/your-no-ip-hostname.ddns.net/fullchain.pem Private key path: /etc/letsencrypt/live/your-no-ip-hostname.ddns.net/privkey.pem Click \u0026ldquo;Save configuration\u0026rdquo;. The page will reload on a secure https:// connection! ## Chapter 7: Automating SSL Renewal (Cron Job Magic) ‚ú® Let\u0026rsquo;s Encrypt certificates last for 90 days. We can tell our server to automatically renew them.\nOpen the Cron Editor: In SSH, run sudo crontab -e and choose nano as your editor. Add the Renewal Job: Add this line to the bottom of the file. It tells the server to try renewing the certificate every day at 2:30 AM. 30 2 * * * systemctl stop AdGuardHome.service \u0026amp;\u0026amp; certbot renew --quiet \u0026amp;\u0026amp; systemctl start AdGuardHome.service Save and exit (Ctrl+X, then Y, then Enter). Your server will now keep its certificate fresh forever! ## Chapter 8: Testing Your New Superpowers (DoH \u0026amp; DoT) üß™ For a direct confirmation, I used these commands on my computer:\nDNS-over-HTTPS (DoH) Test: This test checks if the secure web endpoint for DNS is alive.\ncurl -v [https://your-no-ip-hostname.ddns.net/dns-query](https://your-no-ip-hostname.ddns.net/dns-query) I got a \u0026ldquo;405 Method Not Allowed\u0026rdquo; error, which sounds bad but is actually great news. It means I successfully connected to the server, which correctly told me I didn\u0026rsquo;t send a real query. The connection works!\nDNS-over-TLS (DoT) Test: This checks the dedicated secure port for DNS. I used a tool called kdig.\n# I had to install it first with: sudo apt install knot-dnsutils kdig @your-no-ip-hostname.ddns.net +tls-ca +tls-host=your-no-ip-hostname.ddns.net example.com The command returned a perfect DNS answer for example.com, confirming the secure tunnel was working.\n## Chapter 9: Protecting Your Kingdom (Router \u0026amp; Phone Setup) üè∞ Now, let\u0026rsquo;s point your devices to their new guardian.\nOn Your Home Router: Log in to your router\u0026rsquo;s admin page, find the DNS settings, and enter your server\u0026rsquo;s Elastic IP as the primary DNS server. Leave the secondary field blank! This forces all devices on your Wi-Fi to be protected. Then, restart your router. On Your Mobile Phone: Android: Go to Settings -\u0026gt; Network -\u0026gt; Private DNS. Choose \u0026ldquo;Private DNS provider hostname\u0026rdquo; and enter your No-IP hostname (my-dns.ddns.net). This gives you ad-blocking everywhere, even on cellular data! iOS: You can use a profile to configure DoH. A simple way is to use a site like AdGuard\u0026rsquo;s DNS profile generator, but enter your own server\u0026rsquo;s DoH address (https://my-dns.ddns.net/dns-query). ## Chapter 10: The Ultimate Safety Net (Creating a Snapshot) üì∏ Finally, let\u0026rsquo;s back up our perfect setup.\nIn the EC2 Console, go to your instance details. Click the \u0026ldquo;Storage\u0026rdquo; tab and click the \u0026ldquo;Volume ID\u0026rdquo;. Click \u0026ldquo;Actions\u0026rdquo; -\u0026gt; \u0026ldquo;Create snapshot\u0026rdquo;. Give it a description, like AdGuard-Working-Setup-Backup. If you ever mess something up, you can use this snapshot to restore your server to this exact working state in minutes.\n## Bonus Chapter: Common Troubleshooting Tips If things aren\u0026rsquo;t working, here are a few common pitfalls to check:\nBrowser Overrides Everything: If one device isn\u0026rsquo;t blocking ads, check its browser settings! Modern browsers like Chrome have a \u0026ldquo;Secure DNS\u0026rdquo; feature that can bypass your custom setup. You may need to turn this off. Check Your Laptop\u0026rsquo;s DNS: Make sure your computer\u0026rsquo;s network settings are set to \u0026ldquo;Obtain DNS automatically\u0026rdquo; so it listens to the router. A manually set DNS on your PC will ignore the router\u0026rsquo;s settings. Beware of IPv6: If you run into trouble on one device, try disabling IPv6 in that device\u0026rsquo;s Wi-Fi adapter properties to force it to use your working IPv4 setup. ## It‚Äôs a Wrap! And there you have it! You\u0026rsquo;ve successfully built a personal, secure, ad-blocking DNS server in the cloud. You\u0026rsquo;ve learned about cloud computing, firewalls, DNS, SSL, and automation. Go enjoy a faster, cleaner, and more private internet experience.\n","permalink":"http://localhost:1313/projects/adguard-updated/","summary":"\u003ch1 id=\"your-personal-internet-guardian-how-to-build-a-free-ad-blocker-in-the-cloud-\"\u003eYour Personal Internet Guardian: How to Build a FREE Ad-Blocker in the Cloud! üöÄ\u003c/h1\u003e\n\u003cp\u003eHey everyone! A while back, I wrote a guide on setting up AdGuard Home on Linode. The world of tech moves fast, and it\u0026rsquo;s time for an upgrade! Today, we\u0026rsquo;re going to build our own powerful, network-wide ad-blocker using \u003cstrong\u003eAmazon Web Services (AWS)\u003c/strong\u003e, and we\u0026rsquo;ll make it secure with our own domain and SSL certificate.\u003c/p\u003e\n\u003cp\u003eThink of this as building a digital gatekeeper for your internet. Before any ads, trackers, or malicious sites can reach your devices, our AdGuard Home server will slam the door shut. The best part? This works on your phone, laptop, smart TV‚Äîanything on your network‚Äîwithout installing a single app on them.\u003c/p\u003e","title":"How I Built My Own Ad-Blocking DNS Server in the Cloud (2025 Updated Edition!)"},{"content":"New Project Alert: Running a Powerful AI Locally with Docker! Hey everyone, Prajwol here.\nI\u0026rsquo;ve always been fascinated by the incredible advancements in AI and large language models. While cloud-based models are powerful, I was really curious about what it would take to run a high-performance model right on my own machine. This gives you ultimate privacy, control, and the ability to experiment without limits.\nSo, for my latest project, I decided to dive in and get the DeepSeek-R1 model, a powerful AI, up and running locally using Docker.\nDocker is an amazing tool that lets you package up applications and all their dependencies into a neat little box called a container. This means you can run complex software without the headache of complicated installations or conflicts with other programs on your system. It was the perfect way to tame this powerful AI and get it running smoothly on my Ubuntu machine.\nThe process was a fantastic learning experience, covering everything from setting up Docker to pulling the model and interacting with the AI. It‚Äôs amazing to have that kind of power running on your own hardware.\nI‚Äôve documented my entire process in a detailed, step-by-step guide. If you‚Äôre interested in local AI and want to see how you can run a powerful model yourself, be sure to check it out!\nYou can find the full project guide right here! Let me know what you think of this one!\nPublished: February, 2023\n","permalink":"http://localhost:1313/blog/running-deepseek-r1-on-docker-container-on-ubuntu/","summary":"\u003ch1 id=\"new-project-alert-running-a-powerful-ai-locally-with-docker\"\u003eNew Project Alert: Running a Powerful AI Locally with Docker!\u003c/h1\u003e\n\u003cp\u003eHey everyone, Prajwol here.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;ve always been fascinated by the incredible advancements in AI and large language models. While cloud-based models are powerful, I was really curious about what it would take to run a high-performance model right on my own machine. This gives you ultimate privacy, control, and the ability to experiment without limits.\u003c/p\u003e\n\u003cp\u003eSo, for my latest project, I decided to dive in and get the \u003cstrong\u003eDeepSeek-R1\u003c/strong\u003e model, a powerful AI, up and running locally using \u003cstrong\u003eDocker\u003c/strong\u003e.\u003c/p\u003e","title":"Running a Powerful AI Locally with Docker!"},{"content":"My First Cloud Ad-Blocker: A Look Back at AdGuard Home on Linode Hey everyone, Prajwol here.\nAs I continue to explore different cloud projects, I often think back to the ones that had the biggest impact on my day-to-day life. One of the very first projects that truly changed my internet experience was setting up my own ad-blocking DNS server using AdGuard Home on a Linode instance.\nMy goal was to find a simple, cost-effective way to block ads and trackers across my entire home network. I wanted a \u0026ldquo;set it and forget it\u0026rdquo; solution that would cover every device‚Äîfrom my phone to my smart TV‚Äîwithout needing to install an app on each one. Linode (now Akamai) was the perfect platform for this: straightforward, powerful, and great for hosting a lightweight service like AdGuard Home.\nThe process of spinning up a small server, running a single installation script, and then seeing the query logs light up with blocked requests was incredibly satisfying. It felt like I had taken back a real measure of control over my own network.\nThis project remains a fantastic entry point for anyone wanting to get started with self-hosting and network privacy. I\u0026rsquo;ve kept the original, detailed guide for anyone who wants to follow along.\nYou can find the full step-by-step project guide here! It‚Äôs a rewarding project that delivers tangible results almost immediately. Let me know if you give it a try!\nPublished: Friday, August 22, 2025\n","permalink":"http://localhost:1313/blog/adguard-home-on-cloud/","summary":"\u003ch1 id=\"my-first-cloud-ad-blocker-a-look-back-at-adguard-home-on-linode\"\u003eMy First Cloud Ad-Blocker: A Look Back at AdGuard Home on Linode\u003c/h1\u003e\n\u003cp\u003eHey everyone, Prajwol here.\u003c/p\u003e\n\u003cp\u003eAs I continue to explore different cloud projects, I often think back to the ones that had the biggest impact on my day-to-day life. One of the very first projects that truly changed my internet experience was setting up my own ad-blocking DNS server using AdGuard Home on a Linode instance.\u003c/p\u003e\n\u003cp\u003eMy goal was to find a simple, cost-effective way to block ads and trackers across my entire home network. I wanted a \u0026ldquo;set it and forget it\u0026rdquo; solution that would cover every device‚Äîfrom my phone to my smart TV‚Äîwithout needing to install an app on each one. Linode (now Akamai) was the perfect platform for this: straightforward, powerful, and great for hosting a lightweight service like AdGuard Home.\u003c/p\u003e","title":"My First Cloud Ad-Blocker - A Look Back at AdGuard Home on Linode"},{"content":"What\u0026rsquo;s the buzz about AdGuard Home? Imagine AdGuard Home as your personal internet guardian. This versatile tool blocks ads, trackers, and other online nuisances across all devices connected to your network. Whether you\u0026rsquo;re browsing on your phone, tablet, or computer, AdGuard Home has your back.\nIn today\u0026rsquo;s digital landscape, robust security measures are paramount. Protecting each device shields your family from accidental clicks and malicious attacks, ensuring peace of mind and a secure online environment.\nWhy on the Cloud? While setting up AdGuard Home on your home network is great, installing it on a cloud server like Linode takes things up a notch. Here\u0026rsquo;s why:\nOn-the-Go Protection: Your devices stay protected from ads and trackers, no matter where you are, you can even share it with your family. Centralized Control: Manage and customize your ad-blocking settings from a single dashboard. Enhanced Privacy: Keep your browsing data away from prying eyes. Ready to embark on this ad-free adventure? Let\u0026rsquo;s get started!\nSetting Up The Environment Step 1: Create a Linode Cloud Account Why choose Linode? Through NetworkChuck\u0026rsquo;s referral link, you receive a generous $100 cloud credit - a fantastic start!\nSign Up: Navigate to Linode\u0026rsquo;s signup page and register. Access the Dashboard: Log in and select \u0026lsquo;Linodes\u0026rsquo; from the left-side menu. Create a Linode: Click \u0026lsquo;Create Linode,\u0026rsquo; choose your preferred region, and select an operating system (Debian 11 is a solid choice). Choose a Plan: The Shared 1GB Nanode instance is sufficient for AdGuard Home. Label and Secure: Assign a label to your Linode and set a strong root password. Deploy: Click \u0026lsquo;Create Linode\u0026rsquo; and wait for it to initialize. Once your Linode is up and running, access it via the LISH Console or SSH. (use root as localhost login)\nStep 2: Installing AdGuard Home on Linode Yes, we\u0026rsquo;re already into setting up at this point.\nLog In: Access your Linode using SSH or the LISH Console with your root credentials. Update the system: sudo apt update \u0026amp;\u0026amp; apt upgrade -y Go ahead and copy this command to Install Adguard Home: curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v AdGuard Home is installed and running. You can use CTRL+Shift+V to paste into the terminal.\nStep 3: Configure AdGuard Home Post-installation, you\u0026rsquo;ll see a list of IP addresses with port :3000. Access the Web Interface: Open your browser and navigate to the IP address followed by :3000. If you encounter a security warning, proceed by clicking \u0026ldquo;Continue to site.\u0026rdquo; Initial Setup: Click \u0026lsquo;Get Started\u0026rsquo; and follow the prompts. When uncertain, default settings are typically fine. Set Credentials: Set up the Username and Password. Step 4: Integrate AdGuard Home with Your Router After this, your AdGuard Home is running, but in order to use it on your devices you need to set up inside your home router for all your devices to be protected. For that, I can\u0026rsquo;t walk you through each and every router\u0026rsquo;s settings, but the steps are pretty similar.\nFind your router IP address, you should be able to find it on the back of your router (commonly 192.168.0.1 or 192.169.1.1) enter it into your browser. Login into your router using the credentials mentioned in the back of your router; the default is often admin for both username and password. I suggest you change your default password. Configure DNS Settings: Enable DHCP Server: Ensure your router\u0026rsquo;s DHCP server is active. Set DNS Addresses: Input your AdGuard Home server\u0026rsquo;s IP as the primary DNS (mine was 96.126.113.207). For secondary DNS, options like 1.1.1.1 (Cloudflare), 9.9.9.9 (Quad9), or 8.8.8.8 (Google) are reliable. Save and apply the changes. Fine-Tuning AdGuard Home If you\u0026rsquo;ve done everything till here you should be good, but for those who enjoy customizations, AdGuard Home offers a plethora of settings. Some of the customization I did are:\nSettings Go to Settings -\u0026gt; General Settings: You can enable Parental Control and Safe Search. You can also make your Statistics last longer than 24hrs which is default. Now on Settings -\u0026gt; DNS Settings By default, it uses DNS from quad9 which is pretty good but I suggest you add more. You can click on the list of known DNS providers, which you can choose from. I used: https://dns.quad9.net/dns-query https://dns.google/dns-query https://dns.cloudflare.com/dns-query Enable \u0026lsquo;Load Balancing\u0026rsquo; to distribute queries evenly. Scroll down to \u0026lsquo;DNS server configuration\u0026rsquo; and enable DNSSEC for enhanced security. Click on Save. Filters DNS blocklists Go to Filters -\u0026gt; DNS blocklists, here you can add a blocklist that people have created and use it to block even more things. By default, AdGuard uses the AdGuard DNS filter, and you can add more.\nClick on Add blocklist -\u0026gt; Choose from the list Don\u0026rsquo;t choose too many from the list cause it may slow your internet requests. These are the blocklists I added. And just like that you are blocking more and more things. DNS rewrites Go to Filters -\u0026gt; DNS rewrites, here you can add your own DNS entries, so I added AdGuard here.\nClick on Add DNS rewrite Type in domain adguardforme.local and your IP address for AdGuard Home. And save it. Now, when I want to go on the AdGuard Home dashboard I just type in adguardforme.local and I\u0026rsquo;m into AdGuard, I don\u0026rsquo;t have to remember the IP address.\nCustom filtering rules Go to Filters -\u0026gt; Custom filtering rules. For some reason when I use Facebook on mobile device stories and videos did not load up, so I added custom filtering rules.\n@@||graph.facebook.com^$important ","permalink":"http://localhost:1313/projects/adguard-home-on-cloud/","summary":"\u003ch1 id=\"whats-the-buzz-about-adguard-home\"\u003eWhat\u0026rsquo;s the buzz about AdGuard Home?\u003c/h1\u003e\n\u003cp\u003eImagine AdGuard Home as your personal internet guardian. This versatile tool blocks ads, trackers, and other online nuisances across all devices connected to your network. Whether you\u0026rsquo;re browsing on your phone, tablet, or computer, AdGuard Home has your back.\u003c/p\u003e\n\u003cp\u003eIn today\u0026rsquo;s digital landscape, robust security measures are paramount. Protecting each device shields your family from accidental clicks and malicious attacks, ensuring peace of mind and a secure online environment.\u003c/p\u003e","title":"Running Private Adguard Server on Cloud (Linode)"},{"content":"What\u0026rsquo;s a Docker Container? Before we dive into setting up DeepSeek-R1, let me explain what a Docker container is. Imagine you have a toy that works perfectly on your birthday but gets broken if you move it to another room. A Docker container is like a magic box that keeps your AI model (the toy) in perfect condition wherever you take it, whether it\u0026rsquo;s running as a background task, on a web server, or even in the cloud.\nDocker containers encapsulate everything required to run an application: the code, dependencies, and environment settings. This ensures consistency across different machines, which is super important for AI models that rely on precise configurations.\nSetting Up The Environment Step 1: Install Ubuntu on Windows (If You Haven\u0026rsquo;t Already) If you\u0026rsquo;re using Windows, the easiest way to get an Ubuntu environment is through the Microsoft Store. Here\u0026rsquo;s how:\nOpen the Microsoft Store and search for Ubuntu. Click Get and let it install. Once installed, open Ubuntu from the Start menu and follow the setup instructions. Update the system: sudo apt update \u0026amp;\u0026amp; sudo apt upgrade Now, you have an Ubuntu terminal running on Windows!\nStep 2: Install Docker (If You Haven\u0026rsquo;t Already) First, let\u0026rsquo;s check if you have Docker installed. Open a terminal and run:\ndocker --version If that returns a version number, congrats! If not, install Docker:\nsudo apt update \u0026amp;\u0026amp; sudo apt install docker.io -y sudo systemctl enable --now docker Step 3: Prerequisites for NVIDIA GPU Install NVIDIA Container Toolkit:\nConfiguring the production repository: curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed \u0026#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g\u0026#39; | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list Update the package list: sudo apt-get update Install the NVIDIA Container Toolkit: sudo apt-get install -y nvidia-container-toolkit Running Ollama Inside Docker Run these commands(P.S. shoutout to NetworkChuck):\ndocker run -d \\ --gpus all \\ -v ollama:/root/.ollama \\ -p 11434:11434 \\ --security-opt=no-new-privileges \\ --cap-drop=ALL \\ --cap-add=SYS_NICE \\ --memory=8g \\ --memory-swap=8g \\ --cpus=4 \\ --read-only \\ --name ollama \\ ollama/ollama Running DeepSeek-R1 Locally Time to bring DeepSeek-R1 to life locally and containerized:\ndocker exec -it ollama ollama run deepseek-r1 or you can run other versions of deepseek-r1 just by typing in the version at the end after a colon(:)\ndocker exec -it ollama ollama run deepseek-r1:7b After this, play around with the AI, if you wanna exit just type:\n/bye Starting Deepseek-R1 To Start Deepseek-R1 from next time go to Ubuntu and type:\ndocker start ollama this will start ollama docker container; then type:\ndocker exec -it ollama ollama run deepseek-r1:7b ","permalink":"http://localhost:1313/projects/running-deepseek-r1-on-docker-container-on-ubuntu/","summary":"\u003ch1 id=\"whats-a-docker-container\"\u003eWhat\u0026rsquo;s a Docker Container?\u003c/h1\u003e\n\u003cp\u003eBefore we dive into setting up DeepSeek-R1, let me explain what a Docker container is. Imagine you have a toy that works perfectly on your birthday but gets broken if you move it to another room. A Docker container is like a magic box that keeps your AI model (the toy) in perfect condition wherever you take it, whether it\u0026rsquo;s running as a background task, on a web server, or even in the cloud.\u003c/p\u003e","title":"Dive into AI Fun: Running DeepSeek-R1 on a Docker Container on Ubuntu"},{"content":"Description I joined AbbVie initially as a contractor and quickly demonstrated the skills and dedication that led to my conversion to a full-time position. In my role, I stepped into a high-stakes production environment where precision and operational stability are paramount. My work centered on the optimization and maintenance of sophisticated, machine learning-based visual inspection systems. I was responsible for fine-tuning these models, analyzing their performance data, and troubleshooting complex technical issues across both hardware and software, including the POM and PCE systems.\nThis wasn\u0026rsquo;t just about keeping machines running; it was about enhancing them. By applying a systematic, data-driven approach, I contributed to a 30% reduction in product waste, a metric that translates directly to improved efficiency and sustainability. Working within strict GMPs and utilizing systems like SAP for material tracking, I learned to balance technical problem-solving with rigorous compliance, ensuring that every action contributed to the stability and reliability of mission-critical operations.\n","permalink":"http://localhost:1313/experience/abbvie/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eI joined AbbVie initially as a contractor and quickly demonstrated the skills and dedication that led to my conversion to a full-time position. In my role, I stepped into a high-stakes production environment where precision and operational stability are paramount. My work centered on the optimization and maintenance of sophisticated, machine learning-based visual inspection systems. I was responsible for fine-tuning these models, analyzing their performance data, and troubleshooting complex technical issues across both hardware and software, including the POM and PCE systems.\u003c/p\u003e","title":"Operator III"},{"content":"Description As my first professional role after moving to the United States, my position at FedEx was a crucial step in adapting my technical skills to a new corporate environment. My journey began as a contractor, where my performance and analytical skills in a fast-paced setting led to my transition to a full-time Associate role. At the device testing center, I was on the front lines of quality assurance for a wide array of consumer electronics. I conducted comprehensive, systematic testing on mobile devices, smartwatches, and routers, executing detailed test plans to identify hardware vulnerabilities, software bugs, and non-compliance with network standards.\nMy responsibilities included meticulously documenting my findings, reproducing bugs to assist developers, and providing clear, actionable reports to engineering teams. This collaborative process was crucial in accelerating the repair cycle and ensuring that products met the highest standards of quality and security before reaching the market. The role sharpened my analytical skills and gave me a deep appreciation for the importance of rigorous testing in the software development lifecycle.\n","permalink":"http://localhost:1313/experience/fedex/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eAs my first professional role after moving to the United States, my position at FedEx was a crucial step in adapting my technical skills to a new corporate environment. My journey began as a contractor, where my performance and analytical skills in a fast-paced setting led to my transition to a full-time Associate role. At the device testing center, I was on the front lines of quality assurance for a wide array of consumer electronics. I conducted comprehensive, systematic testing on mobile devices, smartwatches, and routers, executing detailed test plans to identify hardware vulnerabilities, software bugs, and non-compliance with network standards.\u003c/p\u003e","title":"Product Testing Associate"},{"content":"Description As the IT Support Specialist for a bustling international college with over 2,500 students and staff, I was at the heart of the campus\u0026rsquo;s technical operations. My role was dynamic and comprehensive, involving end-to-end technical support across a diverse, multi-building campus. I managed the entire user lifecycle, from onboarding new accounts to ensuring smooth system setups across Windows, Linux, and Mac environments. I was the primary point of contact for all technical challenges, resolving Tier 1 and 2 support tickets with a 90% SLA adherence and troubleshooting complex OS issues to minimize downtime.\nMy tenure was marked by significant growth and adaptation. I led the complete technical setup of eight new computer labs, managing everything from hardware deployment and network cabling to software installation and configuration. When the COVID-19 pandemic hit, I was instrumental in transitioning the campus to a hybrid learning model, my first professional experience navigating such a large-scale shift. This required rapidly scaling our remote support capabilities and ensuring both students and faculty could operate effectively from anywhere.\nA cornerstone project of my time was the complete technical overhaul of the newly acquired Kumari Film Hall. I was deeply involved in the project to transform the old cinema into modern lecture halls, which included designing and deploying the entire network infrastructure, setting up AV systems, and ensuring seamless integration with the main campus network.\nTo support these expanding operations, I took the lead in deploying a new UVDesk help desk ticketing system on a CentOS server and embraced automation, utilizing tools like OK Goldy to streamline user creation in Google Workspace. These initiatives standardized processes, improved efficiency, and allowed our team to successfully manage the college\u0026rsquo;s ambitious growth.\n","permalink":"http://localhost:1313/experience/islingtoncollege/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eAs the IT Support Specialist for a bustling international college with over 2,500 students and staff, I was at the heart of the campus\u0026rsquo;s technical operations. My role was dynamic and comprehensive, involving end-to-end technical support across a diverse, multi-building campus. I managed the entire user lifecycle, from onboarding new accounts to ensuring smooth system setups across Windows, Linux, and Mac environments. I was the primary point of contact for all technical challenges, resolving Tier 1 and 2 support tickets with a 90% SLA adherence and troubleshooting complex OS issues to minimize downtime.\u003c/p\u003e","title":"IT Support Specialist"},{"content":"Description Building on my foundational experience, my internship at BlackBox Technologies immersed me in a more complex, project-based environment. I was an integral part of a development team tasked with building a web-based attendance system from the ground up. This role provided me with invaluable hands-on, full-stack experience. I contributed to the backend by assisting senior engineers with the development of business logic in .NET, giving me insight into server-side architecture. Simultaneously, I was responsible for building responsive, user-facing components for the front-end using HTML, CSS, and JavaScript.\nThis experience was a deep dive into the software development lifecycle. I learned how to translate business requirements into technical specifications, participated in code reviews, and understood the synergy between front-end and back-end systems. Working in close collaboration with the engineering team on a single, focused product was an excellent opportunity to apply my skills to a real-world project and solidify my understanding of creating robust, scalable web applications.\n","permalink":"http://localhost:1313/experience/blackbox/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eBuilding on my foundational experience, my internship at BlackBox Technologies immersed me in a more complex, project-based environment. I was an integral part of a development team tasked with building a web-based attendance system from the ground up. This role provided me with invaluable hands-on, full-stack experience. I contributed to the backend by assisting senior engineers with the development of business logic in .NET, giving me insight into server-side architecture. Simultaneously, I was responsible for building responsive, user-facing components for the front-end using HTML, CSS, and JavaScript.\u003c/p\u003e","title":"Web Development Intern"},{"content":"Description My journey into professional software development began at Radiant Infotech, my first internship and job in the tech industry. This role was a pivotal transition from academic theory to real-world application. I was entrusted with supporting the full lifecycle of client websites, which provided an immersive learning experience. My primary responsibility was to develop responsive, pixel-perfect front-end interfaces using HTML, CSS, and Bootstrap, translating design files into functional web components. A key part of this process was using Adobe Photoshop to prepare and optimize web graphics, ensuring both aesthetic quality and optimal performance.\nBeyond the initial development, my role extended to managing website content through various CMS platforms and performing rigorous debugging to ensure cross-browser compatibility and a seamless user experience. This foundational internship was crucial in building my confidence and skills in modern web development, teaching me how to collaborate effectively within a team to deliver high-quality digital products for clients.\n","permalink":"http://localhost:1313/experience/radiantinfotech/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eMy journey into professional software development began at Radiant Infotech, my first internship and job in the tech industry. This role was a pivotal transition from academic theory to real-world application. I was entrusted with supporting the full lifecycle of client websites, which provided an immersive learning experience. My primary responsibility was to develop responsive, pixel-perfect front-end interfaces using HTML, CSS, and Bootstrap, translating design files into functional web components. A key part of this process was using Adobe Photoshop to prepare and optimize web graphics, ensuring both aesthetic quality and optimal performance.\u003c/p\u003e","title":"Web Development Intern"},{"content":"Introduction Welcome to my personal portfolio website. I respect your privacy and am committed to protecting it. This policy outlines what information is collected when you visit my site and how that information is used.\nInformation Collection and Use I collect information in two ways: information you provide directly and anonymous data collected by analytics services.\nPersonal Data You Provide When you request a copy of my resume, you are asked to voluntarily provide your email address.\nHow it\u0026rsquo;s collected: This information is collected via an embedded Google Form. Why it\u0026rsquo;s collected: It is used for the sole purpose of sending the requested resume document to you through an automated process managed by Google Apps Script. How it\u0026rsquo;s used: Your email will not be used for marketing purposes, sold, or shared with any third parties. Anonymous Usage Data To improve the user experience and analyze traffic, this website uses the following third-party services:\nCloudflare Web Analytics: This service collects anonymous traffic data such as page views and country of origin. It does not use cookies or collect personally identifiable information. You can view their privacy policy here.\nMicrosoft Clarity: This service helps me understand user behavior through anonymous session recordings and heatmaps. This data is used to improve the website\u0026rsquo;s design and functionality. You can view their privacy policy here.\nService Providers This website relies on the following third-party service providers to function:\nGoogle Workspace (Forms, Sheets, Apps Script): Used to manage and automate resume requests. Cloudflare \u0026amp; Microsoft: Used for collecting anonymous web analytics. Netlify \u0026amp; GitHub: Used for hosting and deploying the website. Changes to This Privacy Policy I may update this Privacy Policy from time to time. I will notify you of any changes by posting the new Privacy Policy on this page. You are advised to review this page periodically for any changes.\nContact Me If you have any questions about this Privacy Policy, please contact me at: prajwolad18@gmail.com\n","permalink":"http://localhost:1313/privacy-policy/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWelcome to my personal portfolio website. I respect your privacy and am committed to protecting it. This policy outlines what information is collected when you visit my site and how that information is used.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"information-collection-and-use\"\u003eInformation Collection and Use\u003c/h2\u003e\n\u003cp\u003eI collect information in two ways: information you provide directly and anonymous data collected by analytics services.\u003c/p\u003e\n\u003ch3 id=\"personal-data-you-provide\"\u003ePersonal Data You Provide\u003c/h3\u003e\n\u003cp\u003eWhen you request a copy of my resume, you are asked to voluntarily provide your email address.\u003c/p\u003e","title":"Privacy Policy"}]